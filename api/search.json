[{"id":"e2de674c94d8362ed71699d8daa90a57","title":"Mysql主从复制(二)--原理、时延等问题解决","content":"前言在上一篇MySQL主从复制（一）——实战文章中，我们简单的提了一下它的实现原理，随后即开始了其相关的实现实战内容。在本篇文章中，我们主要详细了解数据库主从复制的实现原理以及其在同步过程中存在的时延问题。\n1. 主从复制的形式\n一主一从\n主主复制\n一主多从：扩展系统读取的性能，因为读是在从库读取的；\n多主一从：MySQL5.7开始支持；\n联级复制\n\n2. 主从复制实现原理\n简单来讲，其过程为\n\n主库的任何数据更改都会被记录到二进制日志(binlog)中；\n从库生成两个线程，一个I/O线程，一个SQL线程；\nI/O线程去请求主库 的binlog，并将得到的binlog日志写到relay log（中继日志） 文件中；\n主库会生成一个 log dump 线程，用来给从库 I/O线程传binlog；\nSQL 线程，会读取relay log文件中的日志，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db，来实现主从的操作一致，而最终数据一致；\n\n我们可以发现从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。这就是我们接下来要谈到的主从同步时延问题。\n3.主从同步时延问题的产生时延问题可能会导致我们新增的数据无法读取到，我们针对业务的不同情况来决定我们是否允许有时延，若不允许，则需要我们进行相应的配置去解决。\n3.1 时延情况观察我们在配置好的从库上执行 show slave status\\G;可以看到如下参数：\n\nMaster_Log_File： SLAVE中的I/O线程当前正在读取的主服务器二进制日志文件的名称；\nRead_Master_Log_Pos： 在当前的主服务器二进制日志中，SLAVE中的I/O线程已经读取的位置；\nRelay_Log_File： SQL线程当前正在读取和执行的中继日志文件的名称；\nRelay_Log_Pos： 在当前的中继日志中，SQL线程已读取和执行的位置；\nRelay_Master_Log_File： 由SQL线程执行的包含多数近期事件的主服务器二进制日志文件的名称；\nSlave_IO_Running： I/O线程是否被启动并成功地连接到主服务器上;\nSlave_SQL_Running： SQL线程是否被启动；\nSeconds_Behind_Master： 从属服务器SQL线程和从属服务器I/O线程之间的时间差距，单位以秒计。\n\n从以上的参数中，我们可以观察得知主从数据库的时延情况：\n\n从库同步延迟情况出现的Seconds_Behind_Master不为0，这个数值可能会很大；\nRelay_Master_Log_File和Master_Log_File显示bin-log的编号相差很大，说明bin-log在从库上没有及时同步，所以近期执行的bin-log和当前IO线程所读的bin-log相差很大；\nMySQL的从库数据目录下存在大量mysql-relay-log日志，该日志同步完成之后就会被系统自动删除，存在大量日志，说明主从同步延迟很高。\n\n3.2 主从同步延时问题的产生1）MySQL数据库主从同步延迟原理：主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。有朋友会问：“主库上那个相同的DDL也需要执行10分，为什么slave会延时？”，答案是master可以并发，Slave_SQL_Running线程却不可以。\n2）MySQL数据库主从同步延迟是怎么产生的？当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高次要原因：读写binlog带来的性能影响，网络传输延迟。\n4. 主从同步时延问题解决在讲解时延问题解决时，我们先大概了解MySql主从复制存在的问题：\n\n主库宕机后，数据可能丢失；\n从库只有一个sql thread，在主库写压力大的时候，复制可能存在时延；\n\n4.1 MySql提供的几种主从复制机制：(1)异步复制：MYSQL 默认的复制方式，就是主库写入binlog日志后即可成功返回客户端，无须等待binlog日志传递给从库的过程。但这样一旦主库发生宕机，就有可能出现数据丢失的情况。(2）半同步复制(mysql semi-sync)，解决数据丢失的问题，其原理如下：\n\n事务在主库写完binlog后需要从库返回一个已接受，才返回给客户端。简单的讲就是，主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了\n5.5集成到mysql，以插件的形式存在，需要单独安装；\n确保事务提交后binlog至少传输到一个从库 ；\n不保证从库应用完这个事务的binlog；\n性能有一定的降低，响应时间会更长；\n网络异常或从库宕机，卡主主库，直到超时或从库恢复；\n\n(3)并行复制，解决从库复制延迟的问题，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。其特点如下：\n\n5.6中新增；\n并行是指从库多线程apply binlog ；\n库级别并行应用binlog，同一个库数据更改还是串行的(5.7版并行复制基于事务组)设置set global slave_parallel_workers=10;设置sql线程数为10；\n\n4.2 时延问题解决\n分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。\n\n打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。针对主从延迟，本人的经验如下：\n\n 业务量不大的：主库能处理业务就全放在主库吧，从库只做灾备，备份，对实时性要求不高的统计报表类工作；\n\n已经出现延迟的：一般来说，就慢慢等吧，试图通过重启db之类的操作是无法解决的，还会因为大事务回滚再重做导致花的时间更长；\n\n延迟N天无法解决的：那就重做slave。为什么会延迟N天，难道仅仅是因为从库单线程吗？我感觉大部分都是主库上采用mixed的binlog_format，由于某种限制，无法基于statement，只好row模式复制。那么如果当前sql是全表扫描，传到slave上执行时就是茫茫多次的全表扫描了。一般来说在slave上show proceslist看查看当前的system user正在执行什么，那就是问题SQL。如果pos点一直不动，也可以去主库对应的binlog上查看下执行的是什么东西；\n\n出现延迟时，查看下当前slave的cpu和磁盘状况：一般来说如果从库没有其他业务，单线程的原因，cpu跑满一个核已经是极限了。磁盘io满的话，确认下是否有其他进程或mysql线程影响了它(比如从库正在dump或者超大的sql在执行)，也可以尝试调整下slave上关于io的几个参数；\n\n从库raid卡，务必设置成write back的写策略；\n\n批量的dml操作：批量的dml操作如果不做处理，一般必然会出现延迟，建议业务低峰期执行，并将批量操作做下调整，一次dml 10000行，sleep一会，再dml 10000行。具体的行数和sleep需要自己根据业务确定，能保证从库不延迟就好；\n\n如果还是经常性的短时间延迟，那就尝试加大从库的硬件配置，比如上sata  SSD，pcie等\n\n延迟的监控到位，可通过pt-heart-beat来准确监控延迟值，及时发现查看。\n\n5.5以后版本的，可以考虑采用半同步复制，能解决少量延迟引起的问题，不过对tps性能损耗较大；\n\n升级到mysql 5.7吧，多线程复制即并行复制，几乎完美解决单线程复制引起的从库延迟。\n\n\n5. 总结总的来说，我们可以根据业务场景的不同，合理的选择是否主从复制后再结合读写分离，因为读写分离，是必须要面对时延这一问题，我们可以根据我们需求来确定到底是不是真的需要读写分离，因为我们也同样可以利用redis缓存，或者其它缓存来缓解我们数据库的压力，而将从库仅作为我们的备份，这样我们就不需要去保证从库无时延(即数据与主库实时同步)，所以具体的应用需要符合我们自己的业务场景。\n","slug":"Mysql主从复制-二-原理、时延等问题解决","date":"2020-08-22T06:55:47.000Z","categories_index":"Database","tags_index":"Mysql","author_index":"安安哎呀呀"},{"id":"39ee3696f69f748c543c33dca389e052","title":"Jenkins一键分布式部署springboot项目","content":"一、安装与启动可参考我的上一篇关于jenkins的博客：https://www.jianshu.com/p/cfdf0d90185e\n二、插件准备1.maven项目插件\n查看系统管理–&gt;插件管理–&gt;已安装插件中，过滤框中输入Maven Integration plugin，搜索是否已安装Maven Integration plugin插件；\n若未安装，则可到系统管理--&gt;插件管理--&gt;可选插件中，过滤框中输入Maven Integration plugin，勾选中后点直接安装。\n\n2.节点管理插件\n操作步骤同上，该插件名为Publish Over SSH。\n\n三、配置系统设置1.配置全局工具\n在系统管理--&gt;全局工具配置中，配置Maven、Git、Gradle或Docker等全局工具；\n这一步按需配置(本次例子只需要Maven)，这里以配置Maven为例，如下图；\n由于我虚拟机上并没有安装maven，所以我选择使用的是自动安装。\n\n2.系统设置\njenkins Location:URL为我们虚拟机的ip地址加jenkins启动时开放的端口号(如下图)；\nSSH Server管理(如下图)：若需要多台，点新增再添加即可。需要注意的是，如果没有配置免密登录的话，需要点击高级，勾选Use password authentication, or use a different key ，并在Passphrase/Password这一栏中输入虚拟机远程登录密码。\n\n3.新建maven项目\n4.设置\n设置项目的构建策略与仓库地址\n源码管理设置\n其中Credentials添加如下：输入仓库用户名和密码，描述是为了区分该验证是什么(jenkins会保存一系列我们使用的credentials)可写可不写，推荐写\n构建触发器\nbuild与post steps设置，这里并没有跳过测试，所以会在构建的时候进行测试，若要跳过测试，可以在clean install 后加-DskipTests\n若不知道pom.xml在哪，可以先执行一次构建，构建会把代码克隆下来，我们可以在工作空间中看到，如下图所示\n构建后操作中选择Send build artifacts Over SSH，因为我们在第2步系统设置中将SSH server远程工作目录为/usr/local，此处又将路径设置为jenkins-jar/，由此最终将jar包传输到服务器中的路径是/usr/local/jenkins-jar\n上一步中的Exec command是我们要运行的执令，此处运行了我自己写的一个叫hello.sh的启动脚本，同样，如果我们要一次部署到多台服务器上的话，只需要点击Add Transfer Set再和上图一样设置另一台服务器即可；\n点击保存。\n\n四、启动脚本编写以上jenkins帮我们做了事情主要有如下几个：\n\n从仓库中克隆代码；\nmaven的clean install；\n当build成功后，将相应的文件传输到我们指定的服务器中(此处传输的是jar包)；\n定时重复上述步骤。\n\n由此可见，jenkins并没有使我们项目启动起来，为此我们需要编写启动脚本。脚本内容大致如下(欢迎指正^-^)\n#!&#x2F;bin&#x2F;bash\nfunction killproject()\n&#123;\n#由于我这边多个项目jar包名一致了，所以并没有用 ps -ef | grep jar包名 来查进程id，而是通过端口号来查的\n  project_pid&#x3D;$(netstat -lnp | grep 18099|awk &#39;&#123;print $7&#125;&#39;|cut -d&#x2F; -f1)\n  if [  $project_pid &gt; 0 ];then\n        echo &quot;项目已经启动了，开始关闭项目，项目pid为: $project_pid &quot;\n        kill -9 $(netstat -lnp | grep 18099|awk &#39;&#123;print $7&#125;&#39;|cut -d&#x2F; -f1)\n        echo &#39;项目关闭成功，开始重启项目。。。&#39;\n  else\n        echo &quot;项目未启动，直接启动&quot;\n  fi\n&#125;\nfunction start_project()\n&#123;\n        source &#x2F;etc&#x2F;profile\n        echo &#39;正在启动项目。。。&#39;\n        cd &#x2F;usr&#x2F;local&#x2F;jenkins-jar&#x2F;\n        nohup java -jar demo-0.0.1-SNAPSHOT.jar &gt;warpper.log &amp;2&gt;1 &amp;\n\n&#125;\nfunction check_project()\n&#123;\n  check_pid&#x3D;$(netstat -lnp | grep 18099|awk &#39;&#123;print $7&#125;&#39;|cut -d&#x2F; -f1)\n  if [ $check_pid  &gt; 0 ];then\n        echo &quot;project is start and  pid &#x3D; : $check_pid  &quot;\n  else\n        echo &quot;project are not start&quot;\n  fi\n\n&#125;\nkillproject\nstart_project\nsleep 10\ncheck_project\n\n代码分析，其中：\n\nkillproject()函数作用是查看系统中该项目是否已启动，若已启动，则先kill掉该进程，再启动；若未启动，则直接启动；\nstart_project()函数作用是进入我的jar包存储路径，并后台运行，函数中的source /etc/profile目的是使项目可以后台启动(其实我没加的时候，后台启动项目一直不能用，报错找不到java环境)；\ncheck_project()函数作用是检查项目是否正常启动，可以在jenkins控制台中看到输出信息；\nsleep 10是为了等待我的springboot启动完，然后我们查看它的进程id.\n\n五、构建项目\n点击立即构建，就可以完成项目的自动部署了。\n进入到虚拟机中，使用netstat -lnp | grep 18099可以验证项目是否已启动。\n有时候可能会在控制台输出project are not start，我不是很清楚是否是我设置的睡眠时间短了(为此，我们初次测试可以去虚拟机中查看项目是否启动)。\n\n更新：sleep 10修改成 sleep 30s就好了，之前果然是睡眠时间太短了。\n","slug":"Jenkins一键分布式部署springboot项目","date":"2019-05-13T06:53:30.000Z","categories_index":"Devops","tags_index":"Jenkins,Springboot","author_index":"安安哎呀呀"},{"id":"a48e6dda0c21e40880cba7e763278b04","title":"Docker","content":"什么是Docker?\nDocker是基于Go语言实现的云开源项目。Docker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或者数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。\nDocker引擎的基础是Linux自带的容器（Linux Containers,LXC）技术。IBM对于容器技术的准确描述如下：\n容器有效的将单个操作系统管理的资源划分到孤立的组中，以便更好的在孤立的组之间平衡有冲突的资源使用需求。与虚拟化相比，这样既不需要指令级模拟，也不需要即时编译。容器可以在核心CPU本地运行指令，而不需要任何专门的解释机制。此外，也避免了准虚拟化（paravirtualization）和系统调用替换中的复杂性。\n我们可以将容器理解为一种沙盒。每个容器内运行一个应用，不同的容器相互隔离，容器之间可以建立通信机制。容器的创建和停止都十分快速（秒级），容器自身对资源的需求十分有限，远比虚拟机本身占用的资源少。\nDocker结构\n \ndocker如上图所示，由Client客户端，DOCKER_HOST宿主机，Registry仓库三个部分构成。在客户端部分，用户可以拉取镜像、创建镜像和运行镜像（客户端-服务器的架构。docker client告诉Docker daemon建立、运行、发布你的Docker容器。Docker client和daemon可以运行在一个系统中，或者可以使用Docker client和远程Docker daemon取得联系。docker服务端和docker守护进程之间通过sockets或者REST API交互）。\n运行机制如下描述：\n1.用户在客户端的命令都交给Docker daemon来处理；\n2.如doker run 运行镜像：docker daemon会检查宿主机是否有这个images，若没有则去镜像仓库（Registry）中拉取镜像；\n3.再运行镜像后以容器的形式在宿主机中运行\nDocker给DevOps带来的好处更快速的交付和部署：开发人员可以使用镜像快速的构建标准开发环境；开发完成后，测试和运维人员可以使用开发人员提供的docker镜像快速部署应用，可以避免开发和测试运维人员之间的环境差异导致的部署问题。\n更高校的资源利用：Docker容器的运行不需要额外的虚拟化管理程序支持，它是内核级的虚拟化，在占用更少资源的情况实现更高的性能。\n更方便的迁移和扩展：Docker容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、服务器等。这种兼容使得用户可以在不同的平台之间很方便的完成应用迁移。\n更简单的更新管理：使用Dockerfile，只需要小小的配置修改，就可以替代以往大量的更新工作，并且所有修改都以增量方式进行分发和更新。\n虚拟化与Docker虚拟化的核心是对资源进行抽象，目标往往是为了在同一个机器上运行多个系统或应用，从而提高系统资源的利用率。虚拟化分为很多类型，比如常见的硬件辅助虚拟化（VMware workstation、 KVM等）。Docker所代表的容器虚拟化技术属于操作系统级虚拟化：内核通过创建多个虚拟的操作系统实例（内核和库）来隔离不同的进程。\n传统虚拟化和容器技术结构比较：传统虚拟化技术是在硬件层面实现虚拟化，增加了系统调用链路的环节，有性能损耗；容器虚拟化技术以共享Kernel的方式实现，几乎没有性能损耗。\nDocker三大基本概念imageDocker镜像类似于虚拟机镜像，是一个只读模板，并且包含了文件系统。一个镜像可以只包含一个操作系统环境（比如SUSE镜像），也可以安装了用户程序及其运行环境（比如eBackup镜像）。镜像其实就是一个文件，任何用户程序都可以成为镜像的一部分。\n镜像=操作系统+软件运行环境+用户程序\n \n如上图，一个layer就是一个image，多个image又可以打包成一个image。Image类似一个单链表系统，每个image包含一个指向parent image的指针，没有parent image的image是baseimage（image的指针靠sqlite数据库来保存）。\n最上面的一层（不属于image）是可写的,上面的内容依赖于下面的内容，如果要修改下面的内容，先将下面的内容复制到上面再进行修改。\nImage是创建container的基础。\nContainer容器是从镜像创建的运行实例，可以将其启动、开始。停止、删除，而这些容器都是相互隔离（独立进程），互不可见的。\nRepositoryRepository是image的集合，而Registry是Repository的集合。\nDocker在Centos7环境下的安装\n1.使用root权限登录系统；\n2.更新系统包到最新：\nyum -y update\n3.添加yum仓库\ncat &gt;&#x2F;etc&#x2F;yum.repos.d&#x2F;docker.repo &lt;&lt;-EOF\n[dockerrepo]\nname&#x3D;Docker Repository\nbaseurl&#x3D;https:&#x2F;&#x2F;yum.dockerproject.org&#x2F;repo&#x2F;main&#x2F;centos&#x2F;7\nenable&#x3D;1\ngpgcheck&#x3D;1\ngpgkey&#x3D;https:&#x2F;&#x2F;yum.dockerproject.org&#x2F;gpg\nEOF&lt;&#x2F;pre&gt;\n如下图：\n \n4.安装docker包\nyum install -y docker-engine\nyum install -y docker-selinux\n在使用现成的安装包的时候selinux的安装一定要在docker-engine之前\nyum list installed|grep docker\n5.启动docker\nsystemctl start docker.service\n6.验证docker已经正常安装\ndocker run hello-world\n7.配置docker开机自启动\nsystemctl enable docker.service\nDocker的卸载\n使用yum卸载docker\n1.列出安装的软件包\nyum list installed | grep docker\n2.移除软件包\nyum -y remove docker-engine.x86_64(这命令不会删除镜像，容器，卷组和用户自配置文件)\n3.删除所有镜像，容器和组\nrm -rf /var/lib/docker\nDocker指令\n \ndocker build：创建镜像；\ndocker pull + 镜像名（镜像地址）：获取镜像；\ndocker images：查看本地镜像；\ndocker run + 镜像名 ： 运行镜像 ；\ndocker run -d +镜像名 : 后台运行镜像 ；\ndocker ps : 查看当前运行的容器；\ndocker exec -it + 容器ID：进入容器（如进入Ubuntu）；\ndocker inspect +容器名或容器ID：查看容器所有信息。\nDocker网络\n \n如上图所示Docker网络类型有Bridge、Host 和None\nHost模式：容器直接连接到宿主机上，容器内的网络和宿主机的网络一致；\nBridge模式：以bridge桥段和宿主机相连，启动容器时容器会虚拟出一个网卡，然后连接Bridge再和主机连接。\n开放端口号的形式运行(以下以运行nginx为例)：\ndocker run -d -p 8088:80 nginx &#x2F;&#x2F; -d 指后台运行  -p为开启端口号映射 8088为宿主机端口号 80为nginx监听端口号\ndocker run -d -P(大写P) nginx  &#x2F;&#x2F; -P指开放所有端口号，并随即指定端口号作为映射\n开放端口号遇到的问题：\n \n问题描述：开放端口号失败；\n原因：docker 指定了快速启动方式（百度知道的&#x3D;-&#x3D;）；\n解决办法：重启（restart）Docker后再运行即可。\n\n\nDocker制作镜像示例\n需要用到的操作： Dockerfile的创建，docker build。\n1.创建Dockerfile，示例内容如下：\nfrom tomcat &#x2F;&#x2F;注释:运行于tomcat这个容器\nMAINTAINER Jerry_Liang 1097872779@qq.com &#x2F;&#x2F;作者名Jerry_Liang 联系方式1097872779@qq.com\nCOPY 项目名.war  &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps  &#x2F;&#x2F;将war包拷贝到tomcat容器中\n2.将项目war包放到与Dockerfile的同一目录上；\n3.执行创建镜像命令\ndocker build -t jpress:latest +Dockerfile路径名(如果为当前工作路径则用“.”)\n &#x2F;&#x2F;注释：-t为指定镜像名和后面的latest为镜像标签\nvolume操作\n挂载实现：\n第一种方法：\ndocker run -p 80:80 -d -v F:\\Docker:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx \n&#x2F;&#x2F;注释：-d 指在以守护进程的模式运行（daemon守护进程） -v 即volume将本地指定的文件夹（此处为本机的F盘下的Docker文件夹）挂载到容器的&#x2F;usr&#x2F;share&#x2F;ngixn&#x2F;html 来实现同步（即主机文件夹有变，容器的文件夹也会发生变化）\n第二种方法：\n1.docker create -v F:\\Docker\\data:&#x2F;var&#x2F;mydata --name data_container ubuntu\n &#x2F;&#x2F;注释 --name指定容器名字  ubuntu指定基础镜像 \n2.docker run -it --volumes-from data_container ubuntu &#x2F;bin&#x2F;bash \n &#x2F;&#x2F;注释 -it交互方式运行，直接进入容器\n运行一个好玩的镜像\n运行结果图：\n \n操作：\n首先获取搜索该镜像：docker search whalesay\n然后获取镜像： docker pull docker&#x2F;whalesay\n最后运行：docker run docker&#x2F;whalesay cowsay + 你想说的话（比如我输入的是Docker good）\n分享镜像\ndocker login &#x2F;&#x2F;首先是登录，这样才会有权限分享\ndocker push + 本地镜像名\n参考文章Docker基础：https://blog.csdn.net/weixin_39381833/article/details/80740235\nDocker介绍 ： https://blog.csdn.net/u012299594/article/details/52343910\n视频教程：https://www.imooc.com/video/15727 ； https://www.imooc.com/learn/824\nLinux下的Docker安装教程：https://blog.csdn.net/qq_36892341/article/details/73918672\n参考文章：https://www.cnblogs.com/luchuangao/p/7748575.html?tdsourcetag=s_pctim_aiomsg#_label0\n","slug":"Docker","date":"2018-11-24T06:15:13.000Z","categories_index":"Devops","tags_index":"Docker","author_index":"安安哎呀呀"},{"id":"72eedad54c92985af6f56cde2713a88f","title":"Centos7中的Anaconda安装并开启远程访问jupyter","content":"由于最近在做深度学习相关的学习，需要使用GPU跑代码，但是发现每次需要跑代码的时候都要把代码考上去，而且不怎么方便调试，为此使用Anaconda的jupyter来写代码，可以通过远程服务器上的jupyter来实现本地实时调代码，为此特意查找了相关的远程jupyter资料，特此整理一下。\n1. Anaconda的安装下载：输入以下指令\nwget https:&#x2F;&#x2F;repo.anaconda.com&#x2F;archive&#x2F;Anaconda3-5.3.1-Linux-x86_64.sh\n开始安装\nbash Anaconda3-5.3.1-Linux-x86_64.sh\n根据提示安装即可:1）回车2）接受license terms，即输入yes3）回车确认安装路径（即使用默认安装路径）4）初始化Anaconda3：输入yes即可5）最后他会推荐你装Microsoft VSCode，此处选择no6）使配置文件生效\n#输入以下指令\nsource ~&#x2F;.bashrc\n在终端中输入python来验证环境\n2.开启远程访问jupyter1）安装ipython，jupyter\npip install ipython\npip install jupyter\n2）生成配置文件\n# 到默认的anaconda安装路径中：\ncd &#x2F;root&#x2F;anaconda3&#x2F;etc&#x2F; \njupyter notebook --generate-config\n3）生成加密密码\n#打开ipython\nipython\n在ipython中输入以下代码，然后回车输入我们的密码，会输出加密后的密码\nfrom notebook.auth import passwd\npasswd()\n结果图示例如下：\n将输出的sha1:......复制，一会我们需要用到4）修改默认配置文件vi /root/.jupyter/jupyter_notebook_config.py在文件末尾加入如下图所示的代码\nc.NotebookApp.ip &#x3D; &#39;*&#39; # 允许访问此服务器的 IP，星号表示任意 IP\nc.NotebookApp.password &#x3D; u&#39;sha1:f5...................&#39; # 之前生成的密码 hash 字串\nc.NotebookApp.open_browser &#x3D; False # 运行时不打开本机浏览器\nc.NotebookApp.port &#x3D; 8888 # 使用的端口，随意设置\nc.NotebookApp.enable_mathjax &#x3D; True # 启用 MathJax\n\n5）启动jupyter notebook以下两种启动方式选一种：（推荐第二种，因为第一种一旦关闭xshell远程连接jupyter就会关闭）a.直接启动\n#到jupyter目录下\ncd &#x2F;root&#x2F;anaconda3&#x2F;etc&#x2F;jupyter\n#启动\njupyter notebook --allow-root\n结果图示例如下\nb.后台启动\nnohup jupyter notebook  --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;\n6）开放相应的端口号如果我们服务器的防火墙是开着的话是远程访问不到jupyter的，所以我们要开放相应的端口，如我这配置的是默认的8888端口号，以下是开放端口号指令\n#添加端口\nfirewall-cmd --zone&#x3D;public --add-port&#x3D;8888&#x2F;tcp --permanent\n#重新载入\nfirewall-cmd --reload\n7）远程我们的jupyter在本地服务器中输入ip+端口号，即可访问jupyter示例结果图如下，因为我第一次已经输入过密码了，所以没截图到输入密码的页面，我们第一次远程输入相应的密码即可\n注意默认的工作空间路径为/root/anaconda3/etc/jupyter，即我们新建的文件都在此路径下。\n参考https://blog.csdn.net/qq_43031234/article/details/90201042https://www.jianshu.com/p/e6ae8905833d\n","slug":"Centos7中的Anaconda安装并开启远程访问jupyter","date":"2019-07-14T11:51:32.000Z","categories_index":"深度学习","tags_index":"环境配置","author_index":"安安哎呀呀"},{"id":"689325bb08ea34f3ae386de22ecde592","title":"深度学习GPU服务器环境配置","content":"这几天在跑深度学习有关的代码，弄了一个GPU，找了很多博客去了解如何使用配置才可以使我的代码可以使用GPU去跑。在这一天的忙碌中，终于在晚上把这事搞定了。或许大家会疑惑一个”简单”配置为什么要搞这么久，-_-|| 因为大多资料都是关于Ubuntu系统的配置，关于Centos的资料挺少的，为此，特地记录下本次的配置过程与踩过的坑，留给大家参考。话不多说，开始本教程吧！\n1.系统环境与软件版本系统版本：cento7.5内核版本：3.10.0-862.el7.x86_64软件版本：cuda9.0与cudnn7.0显卡驱动：Nvidia-384.183cuda9.0具体包名：cuda-repo-rhel7-9-0-local-9.0.176-1.x86_64.rpmcudnn7.0具体包名：cudnn-9.0-linux-x64-v7.tgz\n要注意版本的对应性，此处cuda9.0，所以cudnn选择的是cudnn7.0 for cuda9.0即cudnn-9.0-linux-x64-v7.tgz。\n2.相应软件包查询与获取2.1 查看当前系统版本：系统中输入指令cat /etc/redhat-release，结果图示例：\n2.2 查看内核版本输入指令uname -r，结果图示例：\n可以看到我们系统当前的内核版本，如我的为3.10.0-862.el7.x86_64\n2.3 检测是否含有GPU输入指令lspci | grep -i nvidia，结果示例图：可以看到我们系统是否含有GPU，其中图中的Tesla P40是我的GPU对应的版本；\n2.4 获取对应版本的显卡驱动在知道我们的GPU型号后可以去以下网址拿到对获取对应的显卡驱动：点此查询界面如下图所示：\n图中主要是选择我们的GPU类型，比如我的是Tesla的，P系列的Tesla P40的GPU，上图忘记选择cuda9.0了，大家注意选择哈！因为tensorflow是基于cuda9.0的，貌似不支持cuda10(参考他人博客的，有误望指出)\n点击右下方的SEARCH，跳转到如下页面后，点击DOWNLOAD下载即可。\n\n\n使用xftp将显卡驱动上传到我们的服务器中。\n\n2.5  获取cuda9.0下载地址：点此下载按自己系统版本进行选择，选择示例如下图：\n下载完后同样用xftp上传到我们的服务器中。\n2.6 获取cudnn7.0第一种方法：使用压缩包安装\n在服务器中输入如下指令，下载对应的压缩包(即cuda9.0对应的cudnn7.0)wget http://developer.download.nvidia.com/compute/redist/cudnn/v7.0.5/cudnn-9.0-linux-x64-v7.tgz 下载结果示例图：\n更多类型的cudnn系列下载地址参考此处：点此查看\n第二种方法：注意：此处我亲测的是第一种方法的安装法师，第二种方法的话需要大家尝试哈！此处写出来是为了提供该官网下载地址。去NVIDIA官网下载cuda7.0，需要注册账号登录后才可下载：点此下载\n3. 开始安装3.1 安装前准备工作yum安装epel、aliyun、elrepo源\n\nyum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\nyum -y install epel-release\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\nrpm -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm\n\n安装gcc、gcc-c++编译器若已存在则不需要安装yum –y install gccyum -y install gcc-c++\n禁用系统自带的nouveau驱动1）编辑文件vi /etc/default/grub 在其中添加rd.driver.blacklist=nouveau nouveau.modeset=0到GRUB_CMDLINE_LINUX后面，如下图：\n2）输入以下指令生成新的grub配置grub2-mkconfig -o /boot/grub2/grub.cfg 3）编辑/etc/modprobe.d/blacklist.conf(如果不存在则创建)，并添加blacklist nouveauvi /etc/modprobe.d/blacklist.conf 示例图：\n检查内核版本是否一致这一步如果不做好的话(即内核版本不一致)，在安装显卡驱动时就会遇到下图类似的错误：\n\n为此，我们需要检查一下当前运行内核版本与/usr/src/kernels目录下的kernel源码版本是否一致。\n\n检查当前运行内核版本uname -r，结果示例如下图：\n\n\n\n检查/usr/src/kernels目录下的kernel源码版本cd /usr/src/kernelsls\n\n可以看到有对应的版本3.10.0-862.el7.x86_64。其实我之前就踩了这个坑，该文件夹下并没有3.10.0-862.el7.x86_64，只有3.10.0-957.21.3.el7.x86_64版本的源码，导致我装显卡驱动一致失败。\n若版本一致，则可以继续进行下一步了(忽略下面版本不一致时候的操作)。\n若无对应版本的内核源码，可以在此处下载：点此下载\n找到与自己系统运行源码版本一致的包，如我的查找的包为：\n使用xftp将该包传到服务器中，并cd到存储该包的文件夹中，执行以下指令：yum -y install kernel-3.10.0-862.14.4.el7.x86_64.rpm\ncd /usr/src/kernels并查看文件夹是否安装成功。\n重启使刚才的禁用配置生效reboot\n3.2 安装cuda9.0cd到我们存放cuda-repo-rhel7-9-0-local-9.0.176-1.x86_64.rpm的文件夹中，执行安装命令：rpm -i  cuda-repo-rhel7-9-0-local-9.0.176-1.x86_64.rpmyum clean allyum -y install cuda\ncuda的默认安装路径如下：/usr/local/cuda\n设置cuda环境变量vi /etc/profile添加以下内容到末尾：\nexport CUDA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda\nexport LD_LIBRARY_PATH&#x3D;$CUDA_HOME&#x2F;lib64:$CUDA_HOME&#x2F;extras&#x2F;CUPTI&#x2F;lib64:$LD_LIBRAY_PATH\nexport PATH&#x3D;$CUDA_HOME&#x2F;bin:$PATH\n\n使配置文件生效：source /etc/profile\n3.3 安装cudnn7.0cd到我们的压缩包存放文件夹中，解压tar -zxvf  cudnn-9.0-linux-x64-v7.tgz结果如图所示：\n将cuda中的文件复制到cuda toolkit目录中，然后更改文件权限：sudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n至此cuda与cudnn安装完成。\n3.4 安装tensorflow-gpuyum -y install python-pippip install --upgrade pippip install tensorflow-gpu==1.10.1 \n之所以安装1.10.1是因为之前安装1.11.1时，导入tensorflow包使用时会产生段错误：\n起初以为是cudnn版本问题，但实际是tensorflow-gpu版本过高了，降低为1.10.1就好了。\n3.5 验证cuda和cudnn安装无误进入到python shell，输入以下代码import tensorflow按回车，若无报错说明cuda与cudnn已经安装好了。\n3.6 安装NVIDIA显卡驱动重做inittramfs镜像：cp /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bakdracut /boot/initramfs-$(uname -r).img $(uname -r)\ncd到驱动所在目录：chmod +x NVIDIA-Linux-x86_64-384.183.run./NVIDIA-Linux-x86_64-384.183.run --kernel-source-path=/usr/src/kernels/3.10.0-862.el7.x86_64/\n执行后就开始安装驱动了，接受许可：\n\n\n\n\n检查驱动安装情况nvidia-smi，出现如下页面说明已经成功了。\n至此，全部安装已经完成了！可以happy的使用GPU了！\n参考显卡驱动安装：https://blog.csdn.net/xueshengke/article/details/78134991\ncudnn压缩包：https://blog.csdn.net/xiangxianghehe/article/details/79177833\n导入tensorflow报错解决：https://blog.csdn.net/u014561933/article/details/80201552\n官方安装文档：https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux\nhttps://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux\nhttps://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\ncudnn报错解决：https://blog.csdn.net/jy1023408440/article/details/82887479\n环境服务搭建：https://www.jianshu.com/p/bc9c054d1767\n","slug":"深度学习GPU服务器环境配置","date":"2019-07-12T03:27:54.000Z","categories_index":"深度学习","tags_index":"环境配置,GPU服务器","author_index":"安安哎呀呀"},{"id":"4f52276e8a611fec0c598c202290c486","title":"slf4j+log4j2配置日志管理系统","content":"日志解决方案这么多，为何我们选择slf4j+log4j2来作为日志系统呢？首先我们来将常见的日志作对比。\n1 日志解决方案对比1.1 log4jLog4j是Apache的一个开放源代码项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、数据库等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。 \nLog4j有7种不同的log级别，按照等级从低到高依次为：TRACE、DEBUG、INFO、WARN、ERROR、FATAL、OFF。如果配置为OFF级别，表示关闭log。 \nLog4j支持两种格式的配置文件：properties和xml。包含三个主要的组件：Logger、appender、Layout。\n1.2 log4j2Spring Boot1.4以及之后的版本已经不支持log4j，log4j也很久没有更新了，现在已经有很多其他的日志框架对Log4j进行了改良，比如说SLF4J、Logback等。而且Log4j2在各个方面都与Logback非常相似，那么为什么我们还需要Log4j2呢？ \n\n插件式结构。Log4j 2支持插件式结构。我们可以根据自己的需要自行扩展Log4j2我们可以实现自己的appender、logger、filter。 \n配置文件优化。在配置文件中可以引用属性，还可以直接替代或传递到组件。而且支持json格式的配置文件。不像其他的日志框架，它在重新配置的时候不会丢失之前的日志文件。 \nJava 5的并发性。Log4j2利用Java 5中的并发特性支持，尽可能地执行最低层次的加锁。解决了在log4j 1.x中存留的死锁的问题。 \n异步logger。Log4j2是基于LMAX Disruptor库的。在多线程的场景下，和已有的日志框架相比，异步的logger拥有10倍左右的效率提升。 \n\n1.3 logbackLogback，一个“可靠、通用、快速而又灵活的Java日志框架”。logback当前分成三个模块：logback-core，logback- classic和logback-access。logback-core是其它两个模块的基础模块。logback-classic是log4j的一个改良版本。此外logback-classic完整实现SLF4J API使你可以很方便地更换成其它日志系统如log4j或JDK Logging。logback-access访问模块与Servlet容器集成提供通过Http来访问日志的功能。 \n1） logback-core: Joran, Status, context, pattern parsing2）logback-classic: developer logging3） logback-access: The log generated when a user accesses a web-page on a web server. Integrates seamlessly with Jetty and Tomcat.\nLogback相对于log4j的优势： \n1）logback比log4j要快大约10倍，而且消耗更少的内存。2）logback-classic模块直接实现了SLF4J的接口，所以我们迁移到logback几乎是零开销的。3）logback不仅支持xml格式的配置文件，还支持groovy格式的配置文件。相比之下，Groovy风格的配置文件更加直观，简洁。4） logback-classic能够检测到配置文件的更新，并且自动重新加载配置文件。5）logback能够优雅的从I/O异常中恢复，从而我们不用重新启动应用程序来恢复logger。6）logback能够根据配置文件中设置的上限值，自动删除旧的日志文件。7）logback能够自动压缩日志文件。8）logback能够在配置文件中加入条件判断（if-then-else)。可以避免不同的开发环境（dev、test、uat…）的配置文件的重复。9）logback带来更多的filter。10）logback的stack trace中会包含详细的包信息。11）logback-access和Jetty、Tomcat集成提供了功能强大的HTTP-access日志。配置文件：需要在项目的src目录下建立一个logback.xml。注：（1）logback首先会试着查找logback.groovy文件；（2）当没有找到时，继续试着查找logback-test.xml文件；（3）当没有找到时，继续试着查找logback.xml文件；（4）如果仍然没有找到，则使用默认配置（打印到控制台）。\nlogback的一些配置介绍： \n\n控制台输出在Spring Boot中默认配置了ERROR、WARN和INFO级别的日志输出到控制台。我们可以通过两种方式切换至DEBUG级别：在运行命令后加入–debug标志，如：$ java -jar test.jar –debug在application.properties中配置debug=true，该属性置为true的时候，核心Logger（包含嵌入式容器、hibernate、spring）会输出更多内容，但是你自己应用的日志并不会输出为DEBUG级别。\n\n多彩输出如果你的终端支持ANSI，设置彩色输出会让日志更具可读性。通过在application.properties中设置spring.output.ansi.enabled参数来支持。NEVER：禁用ANSI-colored输出（默认项）DETECT：会检查终端是否支持ANSI，是的话就采用彩色输出（推荐项）ALWAYS：总是使用ANSI-colored格式输出，若终端不支持的时候，会有很多干扰信息，不推荐使用\n\n文件输出Spring Boot默认配置只会输出到控制台，并不会记录到文件中，但是我们通常生产环境使用时都需要以文件方式记录。若要增加文件输出，需要在application.properties中配置logging.file或logging.path属性。logging.file，设置文件，可以是绝对路径，也可以是相对路径。如：logging.file=my.loglogging.path，设置目录，会在该目录下创建spring.log文件，并写入日志内容，如：logging.path=../logs日志文件会在10Mb大小的时候被截断，产生新的日志文件，默认级别为：ERROR、WARN、INFO\n\n级别控制在Spring Boot中只需要在application.properties中进行配置完成日志记录的级别控制。配置格式：logging.level.=LEVELlogging.level：日志级别控制前缀，为包名或Logger名LEVEL：选项TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF举例：logging.level.com.test=DEBUG：com.test包下所有class以DEBUG级别输出logging.level.root=WARN：root日志以WARN级别输出\n\n自定义输出格式在Spring Boot中可以通过在application.properties配置如下参数控制输出格式：logging.pattern.console：定义输出到控制台的样式（不支持JDK Logger）logging.pattern.file：定义输出到文件的样式（不支持JDK Logger）\n\n\n2 日志门面slf4jslf4j，即简单日志门面（Simple Logging Facade for Java），不是具体的日志解决方案，而是通过Facade Pattern提供一些Java logging API，它只服务于各种各样的日志系统。按照官方的说法，SLF4J是一个用于日志系统的简单Facade，允许最终用户在部署其应用时使用其所希望的日志系统。作者创建SLF4J的目的是为了替代Jakarta Commons-Logging。 \n实际上，SLF4J所提供的核心API是一些接口以及一个LoggerFactory的工厂类。在使用SLF4J的时候，不需要在代码中或配置文件中指定你打算使用那个具体的日志系统。类似于Apache Common-Logging，SLF4J是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，他在编译时静态绑定真正的Log库。使用SLF4J时，如果你需要使用某一种日志实现，那么你必须选择正确的SLF4J的jar包的集合（各种桥接包）。SLF4J提供了统一的记录日志的接口，只要按照其提供的方法记录即可，最终日志的格式、记录级别、输出方式等通过具体日志系统的配置来实现，因此可以在应用中灵活切换日志系统。\n3 方案选择log4j已经很久没更新了，它的改良版log4j2与Logback都有相应的优化。而slf4j则是门面日志，它不是具体的日志解决方案，为此，常常与具体的实现方案使用，好处就是允许最终用户在部署其应用时使用其所希望的日志系统。那么Logback与log4j2具体选择哪一个呢？以下是我参考的一篇关于log4j2与logback性能测试的文章截图：\n\n为此我选择了slf4j + log4j2来实现项目的日志系统。\n4 具体实现4.1 去除旧的日志依赖 在中加入以下代码，以下主要是排除旧的log4j日志依赖和与门面日志关联的slf4j+log4j12依赖。\n&lt;exclusions&gt;\n  &lt;exclusion&gt;\n             &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;\n             &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;\n   &lt;&#x2F;exclusion&gt;\n\n   &lt;exclusion&gt;\n             &lt;groupId&gt;log4j&lt;&#x2F;groupId&gt;\n             &lt;artifactId&gt;log4j&lt;&#x2F;artifactId&gt;\n   &lt;&#x2F;exclusion&gt;\n&lt;exclusions&gt;\n若以前的配置文件在web.xml中加载了的话需要注释掉：\n#####4.2 添加新的日志解决方案依赖在pom.xml中添加我们的新日志解决方案依赖，若之前项目未加入slf4j的依赖的话需要我们加入相应的slf4j的核心依赖包\n&lt;!--日志系统依赖start--&gt;\n\n       &lt;!-- slf4j核心包--&gt;\n       &lt;dependency&gt;\n           &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;\n           &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;\n           &lt;version&gt;1.7.25&lt;&#x2F;version&gt;\n       &lt;&#x2F;dependency&gt;\n\n       &lt;!--slf4j对应log4j2的中间件,即桥接，告诉slf4j使用log4j2--&gt;\n       &lt;dependency&gt;\n           &lt;groupId&gt;org.apache.logging.log4j&lt;&#x2F;groupId&gt;\n           &lt;artifactId&gt;log4j-slf4j-impl&lt;&#x2F;artifactId&gt;\n           &lt;version&gt;2.10.0&lt;&#x2F;version&gt;\n       &lt;&#x2F;dependency&gt;\n\n       &lt;!--log4j2核心包--&gt;\n       &lt;dependency&gt;\n           &lt;groupId&gt;org.apache.logging.log4j&lt;&#x2F;groupId&gt;\n           &lt;artifactId&gt;log4j-core&lt;&#x2F;artifactId&gt;\n           &lt;version&gt;2.10.0&lt;&#x2F;version&gt;\n       &lt;&#x2F;dependency&gt;\n\n       &lt;dependency&gt;\n           &lt;groupId&gt;org.apache.logging.log4j&lt;&#x2F;groupId&gt;\n           &lt;artifactId&gt;log4j-api&lt;&#x2F;artifactId&gt;\n           &lt;version&gt;2.10.0&lt;&#x2F;version&gt;\n       &lt;&#x2F;dependency&gt;\n\n\n       &lt;!--日志系统依赖end--&gt;\n\n\n5 配置log4j25.1 配置文件格式及读取优先级：Log4j2 配置文件后缀要求为”.xml”、”.json”或者”.jsn”。\n系统选择配置文件的优先级为（从先到后）：\n1）classpath下的名为log4j2-test.json 或者log4j2-test.jsn的文件.2）classpath下的名为log4j2-test.xml的文件.3）classpath下名为log4j2.json 或者log4j2.jsn的文件.4）classpath下名为log4j2.xml的文件.5）如果classpath下没有相关配置文件，则使用默认日志系统.\n配置log4j2.xml在项目中的classpath下新建log4j2的配置文件log4j2.xml。\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot; ?&gt;\n&lt;configuration status&#x3D;&quot;WARN&quot;&gt;\n\n    &lt;Properties&gt; &lt;!-- 配置日志文件输出目录，此配置将日志输出到工程目录下的log4j2_logs文件夹 --&gt;\n        &lt;Property name&#x3D;&quot;LOG_HOME&quot;&gt;\n            log4j2_logs\n        &lt;&#x2F;Property&gt;\n    &lt;&#x2F;Properties&gt;\n\n    &lt;Appenders&gt;\n    &lt;!--这个输出控制台的配置，即System.out --&gt;\n    &lt;Console name&#x3D;&quot;console_out_appender&quot; target&#x3D;&quot;SYSTEM_OUT&quot;&gt;\n        &lt;!-- 控制台只输出level及以上级别的信息(onMatch),其他的直接拒绝(onMismatch) . --&gt;\n        &lt;ThresholdFilter level&#x3D;&quot;INFO&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                         onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;!-- 输出日志的格式 --&gt;\n        &lt;PatternLayout pattern&#x3D;&quot;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&quot; &#x2F;&gt;\n    &lt;&#x2F;Console&gt;\n    &lt;!-- 这个输出控制台的配置，这里输出error级别的信息到System.err，在eclipse控制台上看到的是红色文字 --&gt;\n    &lt;Console name&#x3D;&quot;console_err_appender&quot; target&#x3D;&quot;SYSTEM_ERR&quot;&gt;\n        &lt;ThresholdFilter level&#x3D;&quot;ERROR&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                         onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;PatternLayout pattern&#x3D;&quot;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&quot; &#x2F;&gt;\n    &lt;&#x2F;Console&gt;\n\n\n    &lt;!-- TRACE级别日志 ; 设置日志格式并配置日志压缩格式，压缩文件独立放在一个文件夹内， 日期格式不能为冒号，否则无法生成，因为文件名不允许有冒号，此appender只输出trace级别的数据到trace.log --&gt;\n    &lt;RollingFile name&#x3D;&quot;trace_appender&quot; immediateFlush&#x3D;&quot;true&quot;\n                 fileName&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;trace.log&quot; filePattern&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;trace&#x2F;trace - %d&#123;yyyy-MM-dd HH:mm:ss&#125;.log.gz&quot;&gt;\n        &lt;PatternLayout&gt;\n            &lt;pattern&gt;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&lt;&#x2F;pattern&gt;\n        &lt;&#x2F;PatternLayout&gt;\n        &lt;Policies&gt;\n            &lt;!-- 每个日志文件最大2MB --&gt;\n            &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;2MB&quot; &#x2F;&gt;\n        &lt;&#x2F;Policies&gt;\n        &lt;Filters&gt;\n            &lt;!-- 此Filter意思是，只输出TRACE级别的数据 DENY，日志将立即被抛弃不再经过其他过滤器； NEUTRAL，有序列表里的下个过滤器过接着处理日志；\n                ACCEPT，日志会被立即处理，不再经过剩余过滤器。 --&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;debug&quot; onMatch&#x3D;&quot;DENY&quot;\n                             onMismatch&#x3D;&quot;NEUTRAL&quot; &#x2F;&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;trace&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                             onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;&#x2F;Filters&gt;\n    &lt;&#x2F;RollingFile&gt;\n\n    &lt;!-- DEBUG级别日志 设置日志格式并配置日志压缩格式，压缩文件独立放在一个文件夹内， 日期格式不能为冒号，否则无法生成，因为文件名不允许有冒号，此appender只输出debug级别的数据到debug.log; --&gt;\n    &lt;RollingFile name&#x3D;&quot;debug_appender&quot; immediateFlush&#x3D;&quot;true&quot;\n                 fileName&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;debug.log&quot; filePattern&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;debug&#x2F;debug - %d&#123;yyyy-MM-dd HH:mm:ss&#125;.log.gz&quot;&gt;\n        &lt;PatternLayout&gt;\n            &lt;pattern&gt;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&lt;&#x2F;pattern&gt;\n        &lt;&#x2F;PatternLayout&gt;\n        &lt;Policies&gt;&lt;!-- 每个日志文件最大2MB ; --&gt;\n            &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;2MB&quot; &#x2F;&gt;\n\n            &lt;!-- 如果启用此配置，则日志会按文件名生成新压缩文件， 即如果filePattern配置的日期格式为 %d&#123;yyyy-MM-dd HH&#125;\n                ，则每小时生成一个压缩文件， 如果filePattern配置的日期格式为 %d&#123;yyyy-MM-dd&#125; ，则天生成一个压缩文件 --&gt;\n            &lt;TimeBasedTriggeringPolicy interval&#x3D;&quot;1&quot;\n                                       modulate&#x3D;&quot;true&quot; &#x2F;&gt;\n\n        &lt;&#x2F;Policies&gt;\n        &lt;Filters&gt;&lt;!-- 此Filter意思是，只输出debug级别的数据 --&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;info&quot; onMatch&#x3D;&quot;DENY&quot;\n                             onMismatch&#x3D;&quot;NEUTRAL&quot; &#x2F;&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;debug&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                             onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;&#x2F;Filters&gt;\n    &lt;&#x2F;RollingFile&gt;\n\n    &lt;!-- INFO级别日志 --&gt;\n    &lt;RollingFile name&#x3D;&quot;info_appender&quot; immediateFlush&#x3D;&quot;true&quot;\n                 fileName&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;info.log&quot; filePattern&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;info&#x2F;info - %d&#123;yyyy-MM-dd HH:mm:ss&#125;.log.gz&quot;&gt;\n        &lt;PatternLayout&gt;\n            &lt;pattern&gt;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&lt;&#x2F;pattern&gt;\n        &lt;&#x2F;PatternLayout&gt;\n        &lt;Policies&gt;\n            &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;2MB&quot; &#x2F;&gt;\n        &lt;&#x2F;Policies&gt;\n        &lt;Filters&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;warn&quot; onMatch&#x3D;&quot;DENY&quot;\n                             onMismatch&#x3D;&quot;NEUTRAL&quot; &#x2F;&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;info&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                             onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;&#x2F;Filters&gt;\n    &lt;&#x2F;RollingFile&gt;\n\n    &lt;!-- WARN级别日志 --&gt;\n    &lt;RollingFile name&#x3D;&quot;warn_appender&quot; immediateFlush&#x3D;&quot;true&quot;\n                 fileName&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;warn.log&quot; filePattern&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;warn&#x2F;warn - %d&#123;yyyy-MM-dd HH:mm:ss&#125;.log.gz&quot;&gt;\n        &lt;PatternLayout&gt;\n            &lt;pattern&gt;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&lt;&#x2F;pattern&gt;\n        &lt;&#x2F;PatternLayout&gt;\n        &lt;Policies&gt;\n            &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;2MB&quot; &#x2F;&gt;\n        &lt;&#x2F;Policies&gt;\n        &lt;Filters&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;error&quot; onMatch&#x3D;&quot;DENY&quot;\n                             onMismatch&#x3D;&quot;NEUTRAL&quot; &#x2F;&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;warn&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                             onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;&#x2F;Filters&gt;\n    &lt;&#x2F;RollingFile&gt;\n\n    &lt;!-- ERROR级别日志 --&gt;\n    &lt;RollingFile name&#x3D;&quot;error_appender&quot; immediateFlush&#x3D;&quot;true&quot;\n                 fileName&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;error.log&quot; filePattern&#x3D;&quot;$&#123;LOG_HOME&#125;&#x2F;error&#x2F;error - %d&#123;yyyy-MM-dd HH:mm:ss&#125;.log.gz&quot;&gt;\n        &lt;PatternLayout&gt;\n            &lt;pattern&gt;%5p [%t] %d&#123;yyyy-MM-dd HH:mm:ss&#125; (%F:%L) %m%n&lt;&#x2F;pattern&gt;\n        &lt;&#x2F;PatternLayout&gt;\n        &lt;Policies&gt;\n            &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;2MB&quot; &#x2F;&gt;\n        &lt;&#x2F;Policies&gt;\n        &lt;Filters&gt;\n            &lt;ThresholdFilter level&#x3D;&quot;error&quot; onMatch&#x3D;&quot;ACCEPT&quot;\n                             onMismatch&#x3D;&quot;DENY&quot; &#x2F;&gt;\n        &lt;&#x2F;Filters&gt;\n    &lt;&#x2F;RollingFile&gt;\n&lt;&#x2F;Appenders&gt;\n\n    &lt;loggers&gt;\n        &lt;!--使appender生效--&gt;\n        &lt;!-- 配置日志的根节点 --&gt;\n        &lt;!-- 定义logger，只有定义了logger并引入了appender，appender才会生效 --&gt;\n        &lt;root level&#x3D;&quot;trace&quot;&gt;\n            &lt;appender-ref ref&#x3D;&quot;console_out_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;console_err_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;trace_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;debug_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;info_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;warn_appender&quot; &#x2F;&gt;\n            &lt;appender-ref ref&#x3D;&quot;error_appender&quot; &#x2F;&gt;\n        &lt;&#x2F;root&gt;\n\n    &lt;&#x2F;loggers&gt;\n&lt;&#x2F;configuration&gt;\n\n6 测试日志输出在我们需要使用日志的类中加入以下代码，导入slf4j相应的包：\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n添加如下代码\nprivate final static Logger logger &#x3D;  LoggerFactory.getLogger(log4j2Test.class);\n这是我使用测试类，若要在别的类使用，使用方法是一致的，只需要做上两步的操作即可：\n运行结果图如下：\n\n注意\n在项目中，可能有的人导包并不是直接导入slf4j的包，而是指定的日志解决方案包，如下\nimport org.apache.log4j.Logger\n这种情况下，我们是直接使用了指定的日志解决方案，并没用发挥我们日志们面的一个作用，这样的话我们下次换日志解决方案的时候，需要修改所有类中导入此包的地方，整个过程会比较麻烦。\n为此，我们应该导入的是日志门面相应的包，这样我们项目更新日志解决方案的时候，只须修改依赖与配置文件即可，而不需要修改其它的代码。\n参考https://www.jianshu.com/p/191273d04d2dhttps://segmentfault.com/a/1190000015568449\n","slug":"slf4j-log4j2配置日志管理系统","date":"2019-07-05T03:27:06.000Z","categories_index":"Java","tags_index":"slf4j,log4j2","author_index":"安安哎呀呀"},{"id":"2fdfe1e1ace8a4912a23a4cbc1c92824","title":"SpringCloud","content":"本文中我们主要介绍微服务开发框架——Spring Cloud。尽管Spring Cloud带有”Cloud”的字样，但它并不是云计算解决方案，而是Spring Boot的基础上构建的，用于快速构建分布式系统的通用模式的工具集。\nSpring Cloud的特点Spring Cloud有以下特点:\n\n约定优于配置；\n适用于各种环境。开发、部署PC Server或各种云环境（例如阿里云、AWS等）均可；\n隐藏了组件的复杂性，并提供声明式、无xml的配置方式；\n开箱即用，快速启动；\n轻量级的组件。Spring Cloud整合的组件大多比较轻量。例如Eureka、Zuul等，都是各自领域轻量级的实现；\n组件丰富，功能齐全。Spring Cloud 为微服务架构提供了非常完整的支持。例如、配置管理、服务发现、断路器、微服务网关等；\n选型中立、丰富。例如，Spring Cloud支持使用Eureka、Zookeeper或Consul实现服务发现；\n灵活。Spring Cloud的组成部分是解耦的，开发人员可以按需灵活挑选技术选型。\n\nSpring Cloud版本简介\n由上图可知，Spring Cloud是以英文单词+SR+数字的形式命名版本号的。那么英文单词和SR分别表示什么呢？因为Spring Cloud是一个综合项目，它包含很多子项目。由于子项目也维护着自己的版本号，Spring Cloud采用了这种命名方式，从而避免与子项目的版本混淆。其中英文单词如Edware是伦敦某地铁站名，它们按照字母顺序发行，可以将其理解为主版本的演进。SR表示”Service Release”，一般表示Bug修复。\n版本兼容性如下\n版本内容\n可参考官方文档：https://spring.io/projects/spring-cloud#overview\nSpring Cloud分布式开发五大组件\n服务发现——Netflix Eureka\n客户端负载均衡——Netflix Ribbon\n断路器——Netflix Hystrix\n服务网关——Netflix Zuul\n分布式配置——Spring Cloud ConfigEureka我的上一篇博客(微服务理论篇)中谈到，对单体应用进行服务拆分得到各个微服务，而这些服务又是相互独立的，那么我们如何知道各个微服务的健康状态、如何知道某个微服务的存在呢？由此、一个拥有服务发现的框架显得尤为重要。这也就是Eureka诞生的原因。\nEureka是由Netflix开发的服务发现框架，本身是一个基于RESTful的服务，主要用于定位运行在AWS域中的中间层服务。\n由两个组件组成：Eureka Server和Eureka Client。Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。Eureka Client即为微服务节点。\nEureka Client启动后，将会注册到Eureka Server中，同时会定时发送心跳（默认无配置情况下为30s），如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，那么Eureka Server将会从服务注册表中把这个节点移除(默认90s)。\nEureka Server之间通过复制的方式完成数据同步，Eureka还提供了客户端缓存机制，即使所有的Eureka Server都挂掉，客户端依然可以利用缓存中的信息消费其他服务的API。\n\n综上，Eureka通过心跳检查、客户端缓存等机制，确保了系统的高可用性、灵活性和可伸缩性。\n####Ribbon\n通过使用Eureka已经实现了微服务的注册与发现。启动各个微服务时，Eureka Client会把自己的网络信息注册到Eureka Server上。似乎一切更美好了一些。然而，这样的架构依然有一些问题，如负载均衡。一般来说，各个微服务都会部署多个实例。那么服务消费者要如何将请求分摊到多个服务提供实例上呢？\n\nRibbon(负载均衡器)的作用正是提供负载均衡机制，当为Ribbon配置服务提供者地址列表后，Ribbon就可以基于某种负载均衡算法，自动地帮助服务消费者去请求。\nRibbon提供的负载均衡算法有多种，例如轮询、加权响应时间、随机和区域感知轮询。\nRibbon与Eureka配合使用时，Ribbon可自动从Eureka Server获取服务提供者地址列表，并基于负载均衡算法，请求其中一个服务提供者示例。(大致架构如下图)\n\nHystrix如果服务提供者相应非常慢，那么消费者对提供者的请求就会被强制等待，知道提供者响应或超时。在高负载场景下，如果不作任何处理，此类问题可能会导致服务消费者的资源耗竭甚至整个系统崩溃。微服务架构的应用系统通常包含多个服务层。微服务之间通过网络进行通信，从而支撑起整个应用系统，因此，微服务之间难免存在依赖关系。而这种由于”基础服务故障”导致”级联故障”的现象称为雪崩效应。如图所示，A最为服务提供者（基础服务），B为A的服务消费者，C和D是B的服务消费者。当A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。那么Hystrix是如何容错的呢？\n\n为网络请求设置超时；\n使用断路器模式：断路器可理解为对容易导致错误操作的代理。这种代理能够统计一段时间内调用失败的次数，并决定是正常请求依赖的服务还是直接返回；断路器可以实现快速失败，如果它在一段时间内检测到许多类似的错误(例如超时)，就会在之后的一段时间内，强迫对该服务的调用快速失败，即不请求所依赖的服务。这样，应用程序就无须再浪费CPU时间去等待长时间的超时。断路器也可以自动诊断依赖的服务是否已经恢复正常，如果发现依赖的服务已经恢复正常，那么就会恢复请求该服务。\n\n以下对该图做个简单讲解：\n\n正常情况下，断路器关闭，可以正常请求依赖的服务；\n当一段时间内，请求失败率达到一定阈值（例如错误率达到50%，或100次/分钟等），断路器就会打开，此时，就不会再去请求依赖的服务；\n断路器打开一段时间后，会自动进入”半开”状态。此时，断路器允许一个请求访问依赖的服务。如果请求能够调用成功，则关闭断路器；否则继续保持打开状态。\n\nZuulZuul作为微服务架构中的微服务网关。微服务架构经过前几个组件的组合，已经有了基本的雏形了，那么我们为什么还要使用微服务网关呢？我们可以想象，一般情况下我们一个业务并不是只调用一个接口就可以完成一个业务需求。如果让客户端直接与各个微服务通信，会有以下问题：\n\n客户端会多次请求不同的微服务，增加了客户端的复杂性；\n存在跨域请求，在一定场景下处理相对复杂；\n认证复杂，每个服务都需要独立认证；\n难以重构，随着项目的迭代，可能需要重新划分微服务，如果直接与微服务通信，那么重构会很难实施；\n\n\n如图，微服务网关封装了应用程序的内部结构，客户端只须跟网关交互，而无须直接调用特定微服务接口。同时，还有以下优点：\n\n易于监控；\n易于认证：可在微服务网关上进行认证，然后再将请求转发到后端的微服务，而无须在每个微服务中进行认证；\n减少了客户端与各个微服务之间的交互次数。\n\nConfig为什么要同一管理微服务配置？对于传统的单体应用，常常使用配置文件管理所有配置。例如一个Spring Boot 项目开发的单体应用，可以将配置内容放到application.yml文件中。如果需要切换环境，可以设置多个Profile,并在启用应用时指定spring.profile.active={profile}。而在微服务架构中，微服务的配置管理一般有以下需求：\n\n集中管理配置：一个使用微服务架构的应用系统可能会包含成百上千个微服务，因此，集中管理配置是很有必要的；\n不同环境不同配置。例如，数据源配置在不同的环境(开发、测试、预发布、生产等)中是不同的;\n运行期间可动态调整：例如，可根据各个微服务的负载情况，动态调整数据源连接池的大小或熔断阈值，并且在调整配置时不停止微服务；\n配置修改后可自动更新：如配置内容发生变化，微服务能够自动更新配置。\n\n\n","slug":"SpringCloud","date":"2019-06-06T03:26:21.000Z","categories_index":"Java","tags_index":"Microservice","author_index":"安安哎呀呀"},{"id":"c2a3674366d1787c09a254e4e4c87ed4","title":"Mysql读写分离","content":"实现MySQL读写分离的前提是我们已经将MySQL主从复制配置完毕，可参考我上一篇关于MySQL主从复制的文章。读写分离实现方式：1）配置多数据源；2）使用mysql的proxy中间件代理工具；第一种方式中，数据库和Application是有一定侵入性的，即我们的数据库更换时，application中的配置文件是需要手动修改的。而第二种方式中，我们可选择mysql proxy固定连接一个数据库，即使数据库地址更换也无需更换项目中的数据库连接配置。同样，在开始配置实现MySQL读写分离之前，我们会遇到一个选型问题，那就是在诸多的MySQL的proxy中间件工具中，如mysql-proxy、atlas、cobar、mycat、tddl、tinnydbrouter和mysql router等，我们该如何取舍呢？所以在择工具实现前，我们先对以上的proxy中间件做一个简单的优劣介绍，以便我们根据不同的场景选择。\n####1.MySQL的proxy中间件工具优劣以下主要对比MyCat和MySQL Router。\n1.1 MyCat是基于阿里巴巴的Cobar方案优化而来，支持半自动化分片，join。为什么叫”半自动化”呢？因为需要DBA对每个表的分片策略进行配置和干涉。优点：\n\n功能较丰富，对读写分离和分库分表都有支持；\n易用，且对原有的应用系统侵入比较小，系统改造比较易于实现；\n支持故障切换；\n\n不足：\n\n在整个系统中，MyCat作为一个单节点来路由其他数据库，在数据库比较多的情况下，MyCat本身的CPU性能压力会越来越大。因此，在生产系统中，MyCat不可避免的会需要一些高可用的手段；\n同样，由于MyCat本身需要解析sql，也需要合并各个数据库返回的结果，本身CPU消耗会比较高，当达到一定临界点时，CPU可能会不堪重负。\n\n为此，在数据库较多的情况下，生产环境下的部署可能是这样的：\n1.2 MySQL RouterMySQL Router是MySQL官方提供的一个轻量级中间件，可以在应用程序与MySQL服务器之间提供透明的路由方式。主要用以解决MySQL主从库集群的高可用、负载均衡、易扩展等问题。Router可以与MySQL Fabric无缝连接，允许Fabric存储和管理用于路由的高可用数据库服务器组，使管理MySQL服务器组更加简单。\nMySQL Router是一个可执行文件，可以与应用程序在同一平台上运行，也可以单独部署。虽然MySQL Router是InnoDB Cluster（MySQL 7.X）的一部分，MySQL 5.6 等版本数据库仍然可以使用Router作为其中间代理层。MySQL Router的配置文件中包含有关如何执行路由的信息。它与MySQL服务器的配置文件类似，也是由多个段组成，每个段中包含相关配置选项。\nMySQL Router是MySQL Proxy的替代方案，MySQL官方不建议将MySQL Proxy用于生产环境，并且已经不提供MySQL Proxy的下载。\n优点：\n\n类似于nginx，位于Application与MySQL Server之间。Application不再直连MySQL Server，而是与Router相连，根据Router的配置，将会把应用程序的读、写请求转发给下游的MySQL Server；\n支持故障切换：当下游某个Server失效时，Router可以将其从Active列表中移除，当其online后再次加入Active列表，即提供了Failover特性；\n当MySQL Server集群拓扑变更时，比如增减Slaves节点，只需要修改Router配置即可，无需修改应用中的数据库连接配置；\n如果MySQL Servers为5.7+版本，且构建为InnoDB Cluster模式，那么Router还能基于metaCache（metaServers）机制，感知MySQL Servers的主从切换、从库增减等集群拓扑变更，而且基于变更能够实现Master自动切换、Slaves列表自动装配等。比如Master失效后，Cluster将会自动选举一个新的Master，此时Router不需要任何调整、可以自动发现此新Master进而继续为应用服务。\n\n不足：\n\nRouter中间件本身不会对请求“拆包”（unpackage），所以无法在Router中间件上实现比如“SQL审计”、“隔离”、“限流”、“分库分表”等功能。但是Router提供了plugin（C语言）机制，我们可以开发自己的plugin来扩展Router的额外特性；\n数据存储在内存中，数据量较大时，硬件需求会提升；\n在非InnoDB Cluster架构模式下，如果主从库拓扑变更，需要手动修改Router配置。且Router不支持“reload”，修改配置后需要重启，这在一定程度上会影响Application的服务可用性。\n\n对比以上两种proxy工具，本文选择了MyCat实现。\n2.MyCat实现MySQL读写分离实验环境| 服务器名称|版本| MySQL版本| IP||——-|—|———–|——-|| MyCat代理中间件| Centos7.3| -| 192.168.ww.ww|| 主数据库| Centos7.3| 5.7| 192.168.xx.xx || 从数据库| Centos7.3| 5.7| 192.168.yy.yy|\n2.1 安装MyCat安装JDK因为MyCat是用java语言编写的，需要JDK支持，JDK安装可参考此博客：点此查看。\n安装MyCat本文下载的版本为Mycat-server-1.6.5-release-20180122220033-linux.tar.gz，点此下载。\n将压缩包用xftp上传到服务器/usr/local/下并解压\ncd &#x2F;usr&#x2F;local&#x2F;\ntar -zxvf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\n配置环境变量vim /etc/profile 在文件末尾加入如下代码，并保存：\nMYCAT_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;mycat\nPATH&#x3D;$MYCAT_HOME&#x2F;bin:$PATH\nexport MYCAT_HOME PATH\n使配置文件生效source /etc/profile；\n2.2配置MyCatMyCat常用配置文件文件位置都在mycat下的conf目录中：|文件|说明||–|–||server.xml|MyCat的配置文件，设置账号、参数等||schema.xml|MyCat对应的物理数据库和数据库表的设置||rule.xml|MyCat分片(分库分表)规则||wrapper.conf|MyCat启动日志信息|\n配置server.xml\nserver.xml中主要配置内容如下(此为默认配置)，其他部分默认即可\n避免图片失效，多粘一份吧=-=！\n&lt;user name&#x3D;&quot;root&quot; defaultAccount&#x3D;&quot;true&quot;&gt;\n                &lt;property name&#x3D;&quot;password&quot;&gt;123456&lt;&#x2F;property&gt;\n                &lt;property name&#x3D;&quot;schemas&quot;&gt;TESTDB&lt;&#x2F;property&gt;\n\n                &lt;!-- 表级 DML 权限设置 --&gt;\n                &lt;!--            \n                &lt;privileges check&#x3D;&quot;false&quot;&gt;\n                        &lt;schema name&#x3D;&quot;TESTDB&quot; dml&#x3D;&quot;0110&quot; &gt;\n                                &lt;table name&#x3D;&quot;tb01&quot; dml&#x3D;&quot;0000&quot;&gt;&lt;&#x2F;table&gt;\n                                &lt;table name&#x3D;&quot;tb02&quot; dml&#x3D;&quot;1111&quot;&gt;&lt;&#x2F;table&gt;\n                        &lt;&#x2F;schema&gt;\n                &lt;&#x2F;privileges&gt;           \n                 --&gt;\n        &lt;&#x2F;user&gt;\n\n        &lt;user name&#x3D;&quot;user&quot;&gt;\n                &lt;property name&#x3D;&quot;password&quot;&gt;user&lt;&#x2F;property&gt;\n                &lt;property name&#x3D;&quot;schemas&quot;&gt;TESTDB&lt;&#x2F;property&gt;\n                &lt;property name&#x3D;&quot;readOnly&quot;&gt;true&lt;&#x2F;property&gt;\n        &lt;&#x2F;user&gt;\n\nMyCat将多个MySQL集群整合起来对外提供服务，提供的服务接口仍然采用MySQL的形式。以上为MyCat对外的”虚拟数据库”配置文件。\n\n以上片段为MyCat默认配置的两个虚拟用户，分别为用户名为root和用户名为user的两个虚拟用户；\n默认用户为root用户，该用户没有配置readOnly的属性，为此拥有读写权限。而用户名为user的用户配置了readOnly的属性为true，为此只有读权限；\nroot的密码被设置为123456，而user的密码被设置为user；\n两者使用的都是TESTDB逻辑库，TESTDB逻辑库的配置在schema.xml中\n\n以上的用户名和密码我们都可以根据个人需求进行修改。\n配置schema.xml\n以下为schema.xml默认的配置文件(其实我删了一小部分schema中的table，因为我们目前做的只是读写分离，因此忽略此部分)：\n&lt;mycat:schema xmlns:mycat&#x3D;&quot;http:&#x2F;&#x2F;io.mycat&#x2F;&quot;&gt;\n        &lt;!--逻辑数据库配置，name与server.xml中配置的数据库对应--&gt;\n        &lt;schema name&#x3D;&quot;TESTDB&quot; checkSQLschema&#x3D;&quot;false&quot; sqlMaxLimit&#x3D;&quot;100&quot;&gt;\n                &lt;!-- 如果只是做读写分离，那么我们就不需要配置这个table --&gt;\n                &lt;!--&lt;table name&#x3D;&quot;travelrecord&quot; dataNode&#x3D;&quot;dn1,dn2,dn3&quot; rule&#x3D;&quot;auto-sharding-long&quot; &#x2F;&gt;--&gt;\n        &lt;&#x2F;schema&gt;\n        &lt;!-- &lt;dataNode name&#x3D;&quot;dn1$0-743&quot; dataHost&#x3D;&quot;localhost1&quot; database&#x3D;&quot;db$0-743&quot;\n                &#x2F;&gt; --&gt;\n        &lt;!--设置实际服务器中数据库--&gt;\n        &lt;dataNode name&#x3D;&quot;dn1&quot; dataHost&#x3D;&quot;localhost1&quot; database&#x3D;&quot;db1&quot; &#x2F;&gt;\n   \n         &lt;!--物理数据库配置--&gt;\n  &lt;dataHost name&#x3D;&quot;localhost1&quot; maxCon&#x3D;&quot;1000&quot; minCon&#x3D;&quot;10&quot; balance&#x3D;&quot;0&quot;\n                          writeType&#x3D;&quot;0&quot; dbType&#x3D;&quot;mysql&quot; dbDriver&#x3D;&quot;native&quot; switchType&#x3D;&quot;1&quot;  slaveThreshold&#x3D;&quot;100&quot;&gt;\n                &lt;heartbeat&gt;select user()&lt;&#x2F;heartbeat&gt;\n                &lt;!-- can have multi write hosts --&gt;\n                &lt;writeHost host&#x3D;&quot;hostM1&quot; url&#x3D;&quot;localhost:3306&quot; user&#x3D;&quot;root&quot;\n                                   password&#x3D;&quot;123456&quot;&gt;\n                        &lt;!-- can have multi read hosts --&gt;\n                        &lt;readHost host&#x3D;&quot;hostS2&quot; url&#x3D;&quot;192.168.1.200:3306&quot; user&#x3D;&quot;root&quot; password&#x3D;&quot;xxx&quot; &#x2F;&gt;\n                &lt;&#x2F;writeHost&gt;\n                &lt;writeHost host&#x3D;&quot;hostS1&quot; url&#x3D;&quot;localhost:3316&quot; user&#x3D;&quot;root&quot;\n                                   password&#x3D;&quot;123456&quot; &#x2F;&gt;\n                &lt;!-- &lt;writeHost host&#x3D;&quot;hostM2&quot; url&#x3D;&quot;localhost:3316&quot; user&#x3D;&quot;root&quot; password&#x3D;&quot;123456&quot;&#x2F;&gt; --&gt;\n        &lt;&#x2F;dataHost&gt;\n&lt;&#x2F;mycat:schema&gt;\n\n简单解释一下上面代码各参数的含义：|参数|说明||–|–||schema|数据库设置，此数据库为逻辑数据库，name与server.xml中的schema对应||dataNodel|分片信息，也就是分库相关配置||dataHost|物理数据库，真正存储数据的数据库|\n每个节点的属性详细说明schema|属性|说明||–|–||name|逻辑数据库名称，与server.xml中的schema对应||checkSQLschema|数据库前缀相关设置，建议看文档，这里暂时设为folse||sqlMaxLimit|select 时默认的limit，避免查询全表||dataNode|分库配置|\ntable|属性|说明||–|–||name|表名，物理数据库中表名||dataNode|表存储到哪些节点，多个节点用逗号分隔。节点为下文dataNode设置的name||primaryKey|主键字段名，自动生成主键时需要设置||autoIncrement|是否自增||rule|分片规则名|\ndataNode|属性|说明||–|–||name|节点名，与table中dataNode对应||dataHost|物理数据库名，与datahost中name对应||database|物理数据库中数据库名|\ndataHost|属性|说明||–|–||name|物理数据库名，与dataNode中dataHost对应||balance|负载均衡策略，0为不开启读写分离，1为开启读写分离||writeType|写入方式||dbType|数据库类型||heartbeat|心跳检测语句，注意语句结尾的分号要加|\n详细介绍以下几个属性值：\n\nbalance=&quot;1&quot;：全部的readHost与stand by writeHost参与select语句的负载均衡；\nwriteType=&quot;0&quot;：所有的写操作都发送到配置文件中的第一个writeHost。(注意：第一个writeHost故障切换到第二个后，即使之后修复了仍然维持第二个为写库)。推荐取值为0，不建议修改；\nswitchType=&quot;1&quot;：1为默认值，即自动切换。\n\n罗列了这么多的属性意思，想必大家已经知道需要配置什么了吧！我们可以根据自己的需求来进行配置，那么接下来我以简单的读写分离来示例配置，以下介绍修改的地方：\n\n在以上默认配置文件schema中并没有设置属性dataNode，为此我们加入dataNode=&quot;dn1&quot;，其中dn1对应&lt;dataNode/&gt;部分中的name属性值；同时，将默认设置的table部分注释掉，最终schema剩余部分如下\n&lt;schema name&#x3D;&quot;test&quot; checkSQLschema&#x3D;&quot;false&quot; sqlMaxLimit&#x3D;&quot;100&quot;  dataNode&#x3D;&quot;dn1&quot; &gt;\n &lt;!-- 本文做的是单纯的读写分离配置为此此处不需要table ，将默认的table注释掉   \n \t&lt;table name&#x3D;&quot;travelrecord&quot; dataNode&#x3D;&quot;dn1&quot; rule&#x3D;&quot;auto-sharding-long&quot; &#x2F;&gt;\n\t--&gt;    \n&lt;&#x2F;schema&gt;\n将&lt;dataNode/&gt;部分中的database属性值改为我们实际储存数据的数据库名称；默认配置中给我们设置了3个dataNode，本环境中只有一个主数据库和一个从数据库，为此我们只保留一个dataNode，如下\n&lt;!--其中database为这是连接的数据库名称，我配置的是我真实数据库中的spring数据库--&gt;\n&lt;dataNode name&#x3D;&quot;dn1&quot; dataHost&#x3D;&quot;localhost1&quot; database&#x3D;&quot;spring&quot; &#x2F;&gt;\n\n&lt;dataHost/&gt;部分的&lt;writeHost&gt;中的host属性值可改可不改，但是url需要改成我们真实数据库的地址，因为我们在主库中进行写操作，为此此处的url改为我们的主数据ip，即url=&quot;192.168.xx.xx&quot;；而user与password两个属性的属性值设置为连接主数据库的用户名和密码；同时，需要将balance的属性值改为1，即balance=&quot;1&quot;，若为0会在测试时发现读写都是在主库执行；\n\n&lt;readHost&gt;部分设置host属性值可改可不改；而url改为我们的从数据库ip，即url=&quot;192.168.yy.yy&quot;，user和password设置为连接从数据库的用户名和密码；\n\n此处因为实验环境是一个主数据库，一个从数据库，为此这里只配置了一个WriteHost和一个readHost；在默认的配置文件中可以看到是可以配置多个的，我们将多余的一个writeHost，最终剩下如下部分\n&lt;dataHost name&#x3D;&quot;localhost1&quot; maxCon&#x3D;&quot;1000&quot; minCon&#x3D;&quot;10&quot; balance&#x3D;&quot;1&quot;\n                         writeType&#x3D;&quot;0&quot; dbType&#x3D;&quot;mysql&quot; dbDriver&#x3D;&quot;native&quot; switchType&#x3D;&quot;1&quot;  slaveThreshold&#x3D;&quot;100&quot;&gt;\n               &lt;heartbeat&gt;select user()&lt;&#x2F;heartbeat&gt;\n               &lt;writeHost host&#x3D;&quot;hostM1&quot; url&#x3D;&quot;192.168.xx.xx:3306&quot; user&#x3D;&quot;root&quot;\n                                  password&#x3D;&quot;password&quot;&gt;\n                       &lt;readHost host&#x3D;&quot;hostS2&quot; url&#x3D;&quot;192.168.yy.yy:3306&quot; user&#x3D;&quot;root&quot; password&#x3D;&quot;password&quot; &#x2F;&gt;\n               &lt;&#x2F;writeHost&gt;\n       &lt;&#x2F;dataHost&gt;\n\n\nlog4j2.xml将日志等级改为debug\n&lt;asyncRoot level&#x3D;&quot;debug&quot; includeLocation&#x3D;&quot;true&quot;&gt;\n            &lt;!--&lt;AppenderRef ref&#x3D;&quot;Console&quot; &#x2F;&gt;--&gt;\n            &lt;AppenderRef ref&#x3D;&quot;RollingFile&quot;&#x2F;&gt;\n&lt;&#x2F;asyncRoot&gt;\n\n至此，整体配置已经完成了，我们开始进行测试！\n3.测试配置是否成功开启MyCat我们要开启MyCat直接输入启动指令即可，后两条指令为我们停止和重启的时候使用；\ncd &#x2F;usr&#x2F;local&#x2F;mycat&#x2F;bin\n# 启动\n.&#x2F;mycat start\n\n#停止\n.&#x2F;mycat stop\n\n#重启\n.&#x2F;mycat restart \n查看端口其中9066为虚拟schema管理端口，用于查看MyCat运行的情况；其中8066为虚拟schema登录端口，用于SQL管理，跟普通MySQL差不多\nnetstat -tnlp\n\n登录MyCat读写分离服务\n# 9066是管理端口\nmysql -u root -p 123456 -h 127.0.0.1 -P 9066\n查看心跳检测\nshow @@help; #查看帮助\nshow @@heartbeat; #查看心跳\n#RS_CODE为1表示心跳正常\n\n查看机器的读写分离配置情况\nshow @@datasource;\n\n可以看到hostM1拥有W写权限，hostS2拥有R读权限\nMyCat读写分离验证登录到MyCat的SQL管理服务：\nmysql -u root -p 123456 -h 127.0.0.1 -P 8066\n可以用简单的指令查看当前数据库\nshow databases;\nuse xxx; # 其中xxx为刚才看到的数据库中的一个\nshow tables; \nselect * from jerry; #为后续做验证准备，这个我们可以按照我们真实表来，此处因为我的数据库中有jerry表，所以以此来示例\n\n\n验证部分有两种思路来验证：1） 在从数据中关闭slave(即关闭主从复制)；然后在mycat管理端中往某个表中插入一条数据；再使用select查询该表，可以看到查询出来的结果中并没有新的那条数据。（解释：因为关闭了主从复制，插入新数据在主库进行，而查询的是从库，为此不会查询到新插入的数据）；2）不关闭slave的主从复制，直接在从库中修改表中的某个值，而主库的值不变，直接使用查询表数据时会发现查询出来的结果是从库表中的数据（可以根据改变的值对比看出）\n本文主要使用第一种思路进行验证：\n\n打开从数据库服务器，并进入mysql中，并停止上篇文章中配置的主从复制；mysql -u root -p #进入从数据库\nstop slave; #关闭主从复制\n再回到我们的mycat安装的服务器中，在已登录的MyCat的SQL管理服务中进行插入一条数据，我的示例如下；insert into jerry (name) values (&#39;liang&#39;)；#我表id是自增的，所以只插入name\nselect * from jerry；#查看\n\n\n可以发现并没有刚插入的数据，我们再打开主数据库，查看是否有更新；（是因为我多次测试，之前没把balance属性值设置为1，导致读写一直是在主库执行，为此主键已经到12了==！）\n\n至此，读写分离验证成功了！第二种小伙伴们可以亲自去尝试一下。对了，验证完记得到从数据库中start salve开启主从复制，避免以后忘了。\n####参考资料https://segmentfault.com/a/1190000009520414https://www.cnblogs.com/joylee/p/7513038.htmlhttps://www.2cto.com/database/201709/676648.html\n","slug":"Mysql读写分离","date":"2019-06-04T06:58:09.000Z","categories_index":"Database","tags_index":"Mysql","author_index":"安安哎呀呀"},{"id":"db73b6318bddc8aeb59536b254b9242c","title":"Mysql主从复制(一)--实战","content":"在开始实际讲解MySQL主从复制如何实现之前，我们可以先思考一个问题！那就是，我们为什么要用数据库主从复制呢？它能为我们解决什么业务问题？在思考过后我们开始进入正题吧！\n1.MySQL主从复制是什么？主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。\n####2.单台MySQL服务器的局限性\n\n无热备数据库，当数据库服务器故障后，所有服务都将暂停，同时可能丢失未能及时存储的数据；\n同样，随着业务的扩展，业务量越来越大，I/O频率过高，这使得数据库的性能越来越差。\n\n####3.主从复制解决的问题\n3.1数据备份提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据；#####3.2高可用\n\n因为数据库服务器中的数据都是相同的，当Master挂掉后，可以指定一台Slave充当Master继续保证服务的运行，因为数据是一致性的（如果当插入时Master就挂掉，可能不一致，因为同步也需要时间）当然这种配置不是简单的把一台Slave充当Master，毕竟还要考虑后续的Slave的数据同步到Master。 \n在主服务器上执行写入和更新，在从服务器上向外提供读功能，达到读写分离的效果，也可以动态地调整从服务器的数量，从而调整整个数据库的性能；读写分离详见另一篇文章\n在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能。\n\n4.主从复制的原理Master服务器将数据的改变记录二进制日志，当Master上的数据发生改变时，则将其改变写入二进制日志中，Salve服务器会在一定时间间隔内对Master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求Master二进制事件，同时主节点为每个I/O线程启动一个线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。\n5.配置实现主从复制环境如下：| 名称|版本| MySQL版本| IP||——-|—|———–|——-|| 主数据库| Centos7.3| 5.7| 192.168.xx.xx || 从数据库| Centos7.3| 5.7| 192.168.yy.yy|\n#####5.1主数据库配置\n\n修改MySQL配置查看数据库配置文件 vi /etc/my.cnf，在[mysqld]下插入如下两行：[mysqld]\nlog-bin&#x3D;mysql-bin # 开启二进制日志\nserver-id&#x3D;1 #设置server-id，需要唯一\n可选参数如下(注意：使用时二选一)：#不同步哪些数据库，除此之外别的都同步\nbinlog-ignore-db &#x3D; information_schema \nbinlog-ignore-db &#x3D; mysql\n\n#只同步哪些数据库，除此之外别的都不同步\nbinlog-do-db &#x3D; test\n重启MySQL，创建用于同步的用户账号进入mysql，创建用户(此用户的目的是让从数据库登录主服务器)并授权：用户名：MySlave，密码：password；systemctl restart mysqld #重启mysql\nmysql -u root -p #进入数据库\n\n# 创建用户，其中用户名后的为从数据ip地址\nmysql&gt; CREATE USER &#39;MySlave&#39;@&#39;192.168.yy.yy&#39; IDENTIFIED BY &#39;password&#39;；\n#分配权限  \nmysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#39;MySlave&#39;@&#39;192.168.yy.yy&#39;；\n#刷新权限\nmysql&gt;FLUSH PRIVILEGES；\n\n查看Master状态，记录二进制文件名和位置可以看到当前记录的二进制文件为mysql-bin.000007，位置为15395.2从数据库配置\n修改mysql配置查看数据库配置文件 vi /etc/my.cnf，在[mysqld]下插入如下两行：[mysqld]\nlog-bin&#x3D;mysql-bin # 开启二进制日志\nserver-id&#x3D;2 #设置server-id，需要唯一\n重启mysql，并进入mysql，进行手动同步mysql&gt; CHANGE MASTER TO\n    MASTER_HOST&#x3D;&#39;192.168.xx.xx&#39;,\n    MASTER_USER&#x3D;&#39;MySlave&#39;,\n    MASTER_PASSWORD&#x3D;&#39;password&#39;,\n    MASTER_LOG_FILE&#x3D;&#39;mysql-bin.000007&#39;,\n    MASTER_LOG_POS&#x3D;1539;\n启动salve同步进程mysql &gt; start slave；\n查看slave状态当Slave_IO_Running: Yes，Slave_SQL_Running: Yes时说明两个线程启动成功，主从复制配置完成了！mysql &gt; show slave status\\G；\n\n\n6.测试主数据库新建jerry表：然后在从数据库中刷新，可以看到新建的表：\n注意：若我们在进行数据库主从复制前，为以下情况的一种：\n\n第一种情况：Master中无任何数据，Slave中也同样无任何数据\n第二种情况：Master中已有表和数据，Slave是无表和无数据的\n\n若为第一种情况，直接配置即可。\n若为第二种情况，会有一个问题(踩过这坑=-=)，那就是如果我们之前有数据，而我们同步时输入的是最新的偏移位置，是会忽略以前的数据操作的，为此如果这个时候我们在Master以前的表中插入新数据，你会发现并不会在Slave中看到该数据，而会产生错误，这时候如果没有在Master的mysql配置文件my.cnf中配置忽略错误slave-skip-errors=1时，Slave_SQL_Running线程会关闭，我们再查看状态会发现其为Slave_SQL_Running: NO。这种情况的解决办法是：手动导出sql文件并在Slave中运行，使得两者为一致状态；然后我们再重新手动同步。\n","slug":"Mysql主从复制-一-实战","date":"2019-06-03T06:55:03.000Z","categories_index":"Database","tags_index":"Mysql","author_index":"安安哎呀呀"},{"id":"4323338174440016aba5335d086cc950","title":"微服务","content":"1 单体应用架构一个归档包(例如war包格式)包含所有功能的应用程序，通常称为单体应用，而架构单体应用的方法，就是单体应用架构。以下为电影售票系统单体架构示意图。\n单体应用存在的一些问题：\n\n复杂性高：项目中可能存在包含模块非常多，但是模块的边界模糊、依赖关系不清晰、代码质量参差不齐、混乱的堆砌在一起，修改起来很容易让人心惊胆战，甚至添加一个简单的功能，或者修改一个bug都会带来隐含的缺陷；\n\n技术债务：随着时间的推移、需求变更和人员更迭，会逐渐形成应用程序的技术债务，并且越积越多。”不坏不修(Not broken,don’t fix)”，这在软件开发中非常的常见，在单体应用中这种思想更甚。已使用的系统设计或代码难以被修改，因为应用程序中的其他模块可能会以意料之外的方式使用它；\n\n 部署频率低：随着代码的增多，构建和部署的时间也会增加。而在单体应用中，每次的功能的变更或缺陷的修复都会导致需要重新部署整个应用。全量部署的方式耗时长、影响范围大、风险高，这使得单体应用项目上线部署的频率较低。而部署频率低又导致两次发布之间会有大量的功能变更和缺陷修复，出错概率比较高。\n\n 可靠性差：某个应用Bug，可能会导致整个应用的崩溃\n\n 扩展能力受限： 单体应用作为一个整体进行扩展，无法根据业务模块的需要进行伸缩。例如，应用中有的模块是计算密集型的，它需要强劲的CPU；有的模块是IO密集型的，需要更大的内存。由于这些模块部署在一起，不得不在硬件的选择上做出妥协。\n\n阻碍技术创新：单体应用往往使用统一的技术平台或方案解决所有的问题，团队中的每个成员都必须使用相同的开发语言和框架，要想引入新技术框架或新技术平台会非常困难。例如，一个使用Struts2构建的单体应用，如果想要换成Spring MVC，毫无疑问切换的成本是非常高的。\n\n\n####2  如何解决单体应用架构存在的问题为了解决以上存在的问题，产生了微服务这种架构设计模式。\n什么是微服务？就目前来看，微服务本身并没有一个严格的定义，每个人对微服务的理解都不同。Martin Fowler在它的博客中是这样描述微服务的：“微服务架构风格是一种将一个单一应用程序开发为一组小型服务的方法，每个服务运行在自己的进程中，服务间通信采用轻量级通信机制(通常用HTTP资源API)。这些服务围绕业务能力构建并且可通过全自动部署机制独立部署。这些服务公用一个最小型的集中式管理，服务可用不同的语言开发，使用不同的数据存储技术。”\n可以从中看到，微服务架构应具备以下特性：\n\n每个微服务可独立运行在自己的进程里；\n一系列独立运行的微服务共同构建起整个系统；\n每个服务为独立的业务开发，一个微服务只关注某个特定的功能，例如订单管理、用户管理等；\n微服务之间通过一些轻量的通信机制进行通信，例如通过RESTful API进行调用；\n可以使用不同的语言与数据储存技术；\n全自动的部署机制。\n\n以电影售票系统为例，使用微服务来架构该应用，架构图如下所示。将整个应用分解为多个微服务，各个微服务独立运行在自己的进程中，并分别有自己的数据库，微服务之间使用REST或者其他协议通信。\n微服务架构的优点与挑战\n相对于单体应用架构来说，微服务架构有着显著的优点。但是，微服务并非是完美的，使用微服务也为我们的工作带来了一定的挑战。\n微服务架构的优点\n\n易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰、代码量较少。开发和维护单个微服务相对简单。而整个应用是由若干个微服务构建而成的，所以整个应用也会被维持一个可控状态；\n\n单个微服务启动较快：单个微服务代码量较少，所以启动会比较快；\n\n局部修改容易部署：单体应用只要有修改，就得重新部署这个服务即可；\n\n技术栈不受限：在微服务架构中，可以结合项目业务以及团队的特点，合理的选择技术栈。例如某些服务可使用关系型数据库MySQL；某些服务有图形计算的需求，可使用Neo4j；甚至可根据需要，部分微服务使用Java开发，部分微服务使用Node.js开发；\n\n按需伸缩：可根据需求，实现细粒度的扩展。例如，系统中的某个微服务遇到了瓶颈，可以结合这个微服务的业务特点，增加内存、升级CPU或者增加节点。\n\n\n但是，完美的东西并不存在，以下是微服务架构面临的问题\n微服务架构面临的问题\n微服务虽然有很多吸引人的地方，但它并不是免费的午餐，使用它同样是有代价的。\n\n运维要求较高：更多的服务意味着更多的运维投入。在单体架构中，只需要保证一个应用正常运行。而在微服务中，需要保证几十甚至几百个服务的正常运行与协作，这给运维带来了很大的挑战。\n\n分布式固有的复杂性：使用微服务构建的是分布式系统。对于一个分布式系统，系统容错、网络延迟、分布式事务等都会带来巨大的挑战。\n\n接口调用成本高：微服务之间通过接口进行通信。如果修改某一个微服务的API，可能所有使用了该接口的微服务都需要做调整。\n\n重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一个功能，从而导致代码重复。尽管可以使用共享库来解决这个问题(例如可以将这个功能封装成公共组件)\n\n\n微服务设计原则\n\n单一职责原则：单一职责原则指的是一个单元(类、方法或者服务等)只应关注整个系统功能中单独、有界限的一部分。单一职责原则可以帮助我们优雅的开发、更敏捷地交付。单一职责原则是SOLID原则之一。\n\n服务自治原则：服务自治是指每个微服务应具备独立的业务能力、依赖于运行环境。在微服务架构中，服务是独立的业务单元，应该与其他服务高度解耦。每个微服务从开发、测试、构建、部署，都应当可以独立运行，而不依赖其他的服务。\n\n轻量级通信机制：微服务之间应该通过轻量级的通信机制进行交互。轻量级的通信机制应该具备两点：首先是它的体量较轻；其次是它应该跨语言、跨平台的。例如我们所熟悉的REST协议，就是一个典型的”轻量级通信机制”；而例如Java的RMI则协议就不符合轻量级通信机制的要求，因为它绑定了Java语言。而微服务架构中，常用的协议有REST、AMQP、STOMP、MQTT等。\n\n微服务粒度：微服务的粒度是难点，也常常是争论的焦点。应当使用合理的粒度划分微服务，而不是一味地把服务做小。代码量的多少不能作为微服务划分的依据，因为不同的微服务本身的业务复杂性不同，代码量也不同。在微服务的设计阶段，就应确定其边界。微服务之间的相对独立并保持松耦合。其中，领域驱动设计（Domain Driven Design，简称DDD）中的”界限上下文”可作为划分微服务边界、确定微服务粒度的重要依据。\n\n\n微服务架构的演进是一个循序渐进的过程。在演进过程中，常常会根据业务的变化，对微服务进行重构，甚至重新划分，从而让架构更加合理。最终，当微服务的开发、部署、测试以及运维的效率很高，并且成本很低时，一个好的微服务架构就形成了。\n下一篇中，将介绍微服务实战。\n","slug":"微服务","date":"2019-05-28T06:54:26.000Z","categories_index":"Java","tags_index":"Microservice","author_index":"安安哎呀呀"},{"id":"c36c9697172955c6c9f9103f2df4da81","title":"SSM整合redis","content":"1.新建redis.properties在classpath下创建redis.properties，内容如下：\nredis.host&#x3D;连接的redis服务器ip地址\nredis.port&#x3D;6379   &#x2F;&#x2F;端口号\nredis.password&#x3D;   &#x2F;&#x2F;你的redis密码\nredis.dbIndex&#x3D;0   &#x2F;&#x2F;db索引，即使用哪个db\nredis.maxIdle&#x3D;50  \nredis.maxTotal&#x3D;100\nredis.maxWaitMillis&#x3D;3000\nredis.testOnBorrow&#x3D;true\nredis.timeout&#x3D;5000\nredis.expiration&#x3D;20 &#x2F;&#x2F;设置关键字过期时间\n2.新建spring-redis.xml&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;\n&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot;\n       xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;\n       xmlns:util&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;util&quot;\n       xmlns:p&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;p&quot; xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot;\n       xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans\n             http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd\n             http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;util\n             http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;util&#x2F;spring-util.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context.xsd&quot;&gt;\n\n    &lt;context:property-placeholder location&#x3D;&quot;classpath:redis.properties&quot;&#x2F;&gt;\n\n    &lt;bean id&#x3D;&quot;poolConfig&quot; class&#x3D;&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;\n        &lt;property name&#x3D;&quot;maxIdle&quot; value&#x3D;&quot;$&#123;redis.maxIdle&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;maxTotal&quot; value&#x3D;&quot;$&#123;redis.maxTotal&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;maxWaitMillis&quot; value&#x3D;&quot;$&#123;redis.maxWaitMillis&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;testOnBorrow&quot; value&#x3D;&quot;$&#123;redis.testOnBorrow&#125;&quot; &#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n    &lt;!-- 配置JedisConnectionFactory --&gt;\n    &lt;bean id&#x3D;&quot;jedisConnectionFactory&quot;\n          class&#x3D;&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt;\n        &lt;property name&#x3D;&quot;hostName&quot; value&#x3D;&quot;$&#123;redis.host&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;port&quot; value&#x3D;&quot;$&#123;redis.port&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;$&#123;redis.password&#125;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;database&quot; value&#x3D;&quot;$&#123;redis.dbIndex&#125;&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;poolConfig&quot; ref&#x3D;&quot;poolConfig&quot; &#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n    &lt;!-- 配置RedisTemplate --&gt;\n    &lt;bean id&#x3D;&quot;redisTemplate&quot; class&#x3D;&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;\n        &lt;property name&#x3D;&quot;connectionFactory&quot; ref&#x3D;&quot;jedisConnectionFactory&quot; &#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n    &lt;!-- 配置RedisCacheManager --&gt;\n    &lt;bean id&#x3D;&quot;redisCacheManager&quot; class&#x3D;&quot;org.springframework.data.redis.cache.RedisCacheManager&quot;&gt;\n        &lt;constructor-arg name&#x3D;&quot;redisOperations&quot; ref&#x3D;&quot;redisTemplate&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;defaultExpiration&quot; value&#x3D;&quot;$&#123;redis.expiration&#125;&quot; &#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n    &lt;!-- 配置RedisCacheConfig --&gt;\n    &lt;bean id&#x3D;&quot;redisCacheConfig&quot; class&#x3D;&quot;com.trace.app.framework.utils.RedisUtil&quot;&gt;\n        &lt;constructor-arg ref&#x3D;&quot;jedisConnectionFactory&quot; &#x2F;&gt;\n        &lt;constructor-arg ref&#x3D;&quot;redisTemplate&quot; &#x2F;&gt;\n        &lt;constructor-arg ref&#x3D;&quot;redisCacheManager&quot; &#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n&lt;&#x2F;beans&gt;\n\n并将该配置文件引入启动配置文件中，如我的是application_context.xml，因为该文件在web.xml做了如下引用\n&lt;context-param&gt;\n        &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt;\n        &lt;param-value&gt;&#x2F;WEB-INF&#x2F;spring&#x2F;application_context.xml&lt;&#x2F;param-value&gt;\n    &lt;&#x2F;context-param&gt;\n所以我将spring-redis.xml引入application_context.xml中\n&lt;import resource&#x3D;&quot;路径&#x2F;spring-redis.xml&quot;&#x2F;&gt;  &#x2F;&#x2F;其中，路径可以是相对的也可以是绝对的\n\n3.创建RedisUtil.class&#x2F;**\n * @Author: JerryLiang\n * @Date: 2019&#x2F;4&#x2F;16 10:00\n **&#x2F;\n@Component\npublic class RedisUtil &#123;\n\n    private volatile JedisConnectionFactory jedisConnectionFactory;\n    private volatile RedisTemplate&lt;String,String&gt; redisTemplate;\n    private volatile RedisCacheManager redisCacheManager;\n\n    private static Logger logger &#x3D; Logger.getLogger(&quot;RedisUtil&quot;);\n\n    public RedisUtil() &#123;\n        super();\n    &#125;\n    public RedisUtil(JedisConnectionFactory jedisConnectionFactory, RedisTemplate&lt;String, String&gt; redisTemplate,\n                     RedisCacheManager redisCacheManager ) &#123;\n        this.jedisConnectionFactory &#x3D; jedisConnectionFactory;\n        this.redisTemplate &#x3D; redisTemplate;\n        this.redisCacheManager &#x3D; redisCacheManager;\n    &#125;\n\n    public JedisConnectionFactory getJedisConnecionFactory() &#123;\n        return jedisConnectionFactory;\n    &#125;\n\n    public RedisTemplate&lt;String, String&gt; getRedisTemplate() &#123;\n        return redisTemplate;\n    &#125;\n\n\n    &#x2F;**\n     * 指定缓存失效时间\n     * @param key 键\n     * @param time 时间(秒)\n     *&#x2F;\n    public boolean expire(String key, long time) &#123;\n     &#x2F;&#x2F;   logger.info(&quot;set-expire-start&quot;);\n        try&#123;\n            if(time &gt; 0)&#123;\n                redisTemplate.expire(key, time, TimeUnit.SECONDS);\n      &#x2F;&#x2F;          logger.info(&quot;set-expire-success&quot;);\n            &#125;\n            return true;\n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     * 普通缓存获取\n     *\n     * @param key 键\n     * @return 值\n     *&#x2F;\n    public Object get(String key) &#123;\n        return key &#x3D;&#x3D; null ? null : redisTemplate.opsForValue().get(key);\n    &#125;\n\n    &#x2F;**\n     *  判断key是否存在\n     * @param key 键\n     * @return true 存在 false 不存在\n     *&#x2F;\n    public boolean hasKey(String key)&#123;\n        try&#123;\n        &#x2F;&#x2F;    logger.info(&quot;SessionId: &quot; + key);\n            return redisTemplate.hasKey(key);\n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     *  删除缓存\n     * @param key\n     *&#x2F;\n    @SuppressWarnings(&quot;unchecked&quot;)\n    public boolean del(String key)&#123;\n        if (key.equals(&quot;&quot;)|| key&#x3D;&#x3D;null) &#123;\n            return false;\n        &#125;else&#123;\n            redisTemplate.delete(key);\n            return true;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     * 普通缓存放入\n     *\n     * @param key   键\n     * @param value 值\n     * @return true成功 false失败\n     *&#x2F;\n    public boolean set(String key, String value) &#123;\n        try &#123;\n            redisTemplate.opsForValue().set(key, value);\n            return true;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n\n    &#125;\n\n    &#x2F;**\n     * 普通缓存放入并设置时间\n     *\n     * @param key   键\n     * @param value 值\n     * @param time  时间(秒) time要大于0 如果time小于等于0 将设置无限期\n     * @return true成功 false 失败\n     *&#x2F;\n    public boolean set(String key, String value, long time) &#123;\n      &#x2F;&#x2F;  logger.info(&quot;set-session-key-start&quot;);\n        try &#123;\n            if (time &gt; 0) &#123;\n                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);\n            &#125; else &#123;\n                set(key, value);\n            &#125;\n        &#x2F;&#x2F;    logger.info(&quot;set-session-key-success&quot;);\n            return true;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     * 根据key 获取过期时间\n     *\n     * @param key 键 不能为null\n     * @return 时间(秒) 返回0代表为永久有效\n     *&#x2F;\n    public long getExpire(String key) &#123;\n        return redisTemplate.getExpire(key, TimeUnit.SECONDS);\n    &#125;\n\n&#125;\n4.测试将RedisUtil注入到我们需要使用的控制层中\n@Autowired\nprivate RedisUtil redisUtil;\n调用\nredisUtil.set(&quot;test&quot;,&quot;ssm&quot;)\n查看结果\n","slug":"SSM整合redis","date":"2019-04-16T06:52:59.000Z","categories_index":"Java","tags_index":"SSM,redis","author_index":"安安哎呀呀"},{"id":"95078be12975a222d9293ee317802e05","title":"LAMP环境搭建","content":"前言Centos7下LAMP的环境搭建！后续会带来集成LNMP的环境搭建！版本：Apache(httpd-2.4.38)+MySQL-5.7.24+PHP-7.1.26\n第一步：配置防火墙\n1.开放80和3306端口：firewall-cmd –zone=public –add-port=80/tcp –permanent (permanent为永久生效，没有此参数重启就 失效)\nfirewall-cmd –zone=public –add-port=80/tcp –permanent\nsystemctl restart firewalld.service 重启防火墙\n2.防火墙的一些相关指令：\n\n第二步：使用源码安装Apache\n安装Apache之前关联依赖的安装1.下载Apache之前需要安装的两个个关联包，apr、apr-util：\n下载链接如下：https://apr.apache.org/\n2.将下载好的apr-1.4.5.tar.gz和apr-util-1.3.12.tar.gz上传到Linux的/usr/local/路径中，并解压：\ntar -zxvf apr-1.4.5.tar.gz\ntar -zxvf apr-util-1.3.12.tar.gz\n3.cd到解压出来的apr-1.4.5中，并执行编译和安装：\n#cd到apr中\ncd &#x2F;usr&#x2F;local&#x2F;apr-1.4.5\n#预编译,并制定安装路径为&#x2F;usr&#x2F;local&#x2F;apr，我们需要提前在&#x2F;usr&#x2F;local&#x2F;中使用mkdir apr来创建apr文件夹\n.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr\n#编译\nmake\n#安装\nmake install\n4.cd到解压出来的apr-util-1.3.12中，并执行编译和安装：\n#cd到apr中\ncd &#x2F;usr&#x2F;local&#x2F;apr-1.4.5\n#预编译,并制定安装路径为&#x2F;usr&#x2F;local&#x2F;apr-util，同上，先创建文件夹apr-util，同时注意后面的--with-apr不可少\n.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util --with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr\n#编译\nmake\n#安装\nmake install\n5.下载pcre-8.37.tar.gz到/usr/local/路径中，下载链接(http://www.pcre.org/):\n#解压\ntar -zxvf pcre-8.37.tar.gz\n#预编译\ncd &#x2F;usr&#x2F;local&#x2F;pcre-8.37\n.&#x2F;configure \n#编译与安装\nmake\nmake install\n5.至此完成了apache编译安装所需依赖的安装：\n若apr和apr-util安装过程中遇到问题，可参考该博客：https://www.jianshu.com/p/a336d3808f52\n安装Apache1.下载httpd包：\nhttpd-2.4.38.tar.gz，下载链接为：http://httpd.apache.org/download.cgi#apache24\n2.使用xftp将httpd-2.4.38.tar.gz压缩包放到/usr/local/下，并解压，命令如下:\ntar -zxvf httpd-2.4.38.tar.gz\n3.cd到http-2.4.38中，并编译安装：\ncd &#x2F;usr&#x2F;local&#x2F;httpd-2.4.38\n#预编译 ，指定安装路径在&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;下，需在&#x2F;usr&#x2F;local&#x2F;下提前mkdir apache2\n.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F; --with-pcre --with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr --with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util\n\n#编译与安装\nmake\nmake install\n4.修改Apache配置文件\ncd &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;conf\n#编辑\nvim httpd.conf\n#搜索ServerName，将注释打开，并修改，如下:\n#ServerName www.example.com:80 修改为 ServerName localhost:80\n4.启动Apache\n#到安装路径下启动Apache\ncd &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin\n#启动\n.&#x2F;apachectl start\n5.打开浏览器，输入虚拟机IP地址访问，若出现It works! 则表明Apache安装成功。\n第三步：安装MySQL\n1.检查是否有Mysql\nLinux中有可能带有mysql数据库，所以我们需要检查一下，再进行安装。首先判断云空间中是否安装了mysql，使用如下命令：rpm -qa | grep mysql如果没有mysql就进行第2步，如果已经有mysql则进行第3步。\n2.安装Mysql服务\n通过yum安装命令进行安装：\nwget http:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql57-community-release-el7-8.noarch.rpm\nyum localinstall mysql57-community-release-el7-8.noarch.rpm\nyum install mysql-community-server\n3.Mysql配置\n\n  启动mysqld服务（第一次启动会初始化配置，之后再启动就不用了）：systemctl start mysqld\n\n  将mysqld服务设置为开机启动：systemctl enable mysqld和systemctl daemon-reload\n\n  安装完毕后，在 /var/log/mysqld.log 文件中会自动生成一个随机的密码，我们需要先取得这个随机密码，以用于登录 MySQL 服务端：grep &quot;password&quot; /var/log/mysqld.log，登录进出之后更改密码即可。\n\n\n\n出现这样的错误就是密码设置的太简单了，需要大小写字母、数字、其他特殊字符组合.\n\n\n  密码设置出问题可以使用下列指令：set global validate_password_policy&#x3D;0; # 设置密码强度为low\nset global validate_password_length&#x3D;4; # 设置密码最低长度为4\nalter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;123456&#39;; # 设置root密码为123456  \\q 退出\n此时我们就可以使用以下命令再输入密码，登录mysql数据库了：mysql -u root -p\n\n特别需要注意的是mysql数据库的数据库文件存放在/var/lib/mysql，端口为3306\n4.远程连接Mysql数据库\n安装完Mysql之后，远程连接数据库之前需要开启Mysql的远程连接权限，执行下面两条语句即可：  1）给予任何主机访问数据的权限\nMySQL&gt;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;mypassword&#39; WITH GRANT OPTION\n2）修改生效\nMySQL&gt;FLUSH PRIVILEGES\n3）退出MySQL服务器\nMySQL&gt;EXIT\n第四步：安装PHP\n安装1.下载安装包php-7.1.26.tar.gz并用xftp上传至服务器/usr/local/路径中：      下载链接：https://www.php.net/2.安装一些依赖库文件：\nyum install libxml2-devel gd-devel libmcrypt-devel libcurl-devel openssl-devel\n3.解压并编译安装：\ncd &#x2F;usr&#x2F;local&#x2F;\n#解压\ntar -zxvf php-7.1.26.tar.gz\n#进入相应文件中\ncd &#x2F;usr&#x2F;local&#x2F;php-7.1.26\n#1.预编译，（注意这里非常关键），首先我们php的安装路径为&#x2F;usr&#x2F;local&#x2F;php7，同样需要先创建#php7这个文件夹，同时，为了得到接下来关联Apache需要使用的libphp7.so 需要添加\n#--with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs这一段，这样我们才能生成需要的libphp7.so\n#2.--enable-fpm也是必须的，该依赖可以使php可以关联Apache或者Nginx一同工作\n.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php7 \\\n --with-curl \\\n --with-freetype-dir \\\n --with-gd \\\n --with-gettext \\\n --with-iconv-dir \\\n --with-kerberos \\\n --with-libdir&#x3D;lib64 \\\n --with-libxml-dir \\\n --with-mysqli \\\n --with-openssl \\\n --with-pcre-regex \\\n --with-pdo-mysql \\\n --with-pdo-sqlite \\\n --with-pear \\\n --with-png-dir \\\n --with-xmlrpc \\\n --with-xsl \\\n --with-zlib \\\n --with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs \\\n --enable-fpm \\\n --enable-bcmath \\\n --enable-libxml \\\n --enable-inline-optimization \\\n --enable-gd-native-ttf \\\n --enable-mbregex \\\n --enable-mbstring \\\n --enable-opcache \\\n --enable-pcntl \\\n --enable-shmop \\\n --enable-soap \\\n --enable-sockets \\\n --enable-sysvsem \\\n --enable-xml \\\n --enable-zip \\\n --enable-mysqlnd\n\n#编译安装\nmake \nmake install\n​\n#查看&#x2F;usr&#x2F;loca&#x2F;apache2&#x2F;modules中是否包含libphp7.so文件\ncd &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;modules&#x2F;\nll\n#若存在，则可以进行下一步，失败的话需要重新排下错误，看是否操作有误。\n#出问题可参考该文章 https:&#x2F;&#x2F;www.zhihu.com&#x2F;question&#x2F;38869703\n4.复制php初始化文件\n#cd到&#x2F;usr&#x2F;local&#x2F;php-7.1.26\ncd &#x2F;usr&#x2F;local&#x2F;php-7.1.26\n#执行如下命令\ncp php.ini-development &#x2F;usr&#x2F;local&#x2F;php7&#x2F;lib&#x2F;php.ini\n5.配置php-fpm\n#php-fpm是支持Apache和Nginx的必要依赖，当修改php.ini后需要重启php-fpm才能生效\ncd &#x2F;usr&#x2F;local&#x2F;php7&#x2F;etc&#x2F;\ncp php-fpm.conf.default php-fpm.conf\n​\ncd &#x2F;usr&#x2F;loca&#x2F;php7&#x2F;etc&#x2F;php-fpm.d\ncp www.conf.default www.conf\n6.php-fpm的启动与关闭\n#首次启动php-fpm\ncd &#x2F;usr&#x2F;local&#x2F;php7&#x2F;sbin&#x2F;\n.&#x2F;php-fpm\n​\n#若已启动过php-fpm则需要用重启的这种方法\n#查看php-fpm的master进程号，如下图所示，master进程号为4384\nps -ef | grep php-fpm\n#使用USR2信号平滑重启所有worker进程并重新载入配置和二进制模块\nkill -USR2 4384\n​\n#php-fpm的关闭，同样是查看进程号,再执行以下命令\nkill -INT 4384\n\n7.测试PHP是否安装成功\n#任意文件夹下创建test.php文件，\ntouch test.php\n#编辑如下内容\n&lt;?php\n phpinfo();\n?&gt;\n#测试,以php的命令执行test.php文件\n&#x2F;usr&#x2F;local&#x2F;php7&#x2F;bin&#x2F;php test.php\n#若有内容输出，则证明已经安装成功了\n关联Apache(关键步骤)1.查看Apache的配置文件是否已经开启关联(一般情况下，安装完成PHP后，会开启，假如没有开启则开启)，可通过第步的测试来测试是否已经开启关联。\n2.开启关联\n#编辑Apache配置文件\nvim &#x2F;usr&#x2F;local&#x2F;apache&#x2F;conf&#x2F;httpd.conf\n​\n#在配置文件中的LoadModule模块中加入如下语句，开启关联\nLoadModule php7_module &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;modules&#x2F;libphp7.so\n​\n#在配置文件末尾加入如下代码\n&lt;FilesMatch \\.php$&gt;\nSetHandler application&#x2F;x-httpd-php\n&lt;&#x2F;FilesMatch&gt;\n​\n#搜索DirectoryIndex，初始只有index.html 更改为如下代码\nDirectoryIndex index.html index.shtml index.cgi index.php index.phtml index.php3\n​\n#找到AddType出，添加如下两行代码\nAddType application&#x2F;x-httpd-php .php .php3 .phtml .inc\nAddType application&#x2F;x-httpd-php-source .phps\n3.测试\n配置文件中的DocumentRoot如下，因此，在/usr/local/apache2/htdocs下创建info.php来测试：（注：该路径即为以后放置我们网站的路径）\n\n#到如下路径中\ncd &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs\n#创建info.php\nvim info.php\n#输入如下内容\n&lt;?php\n phpinfo();\n?&gt;\n#保存并退出编辑。\n在浏览器中输入虚拟机访问地址加info.php：ip/info.php\n若出现如下图所示，则关联成功了\n\n关联Mysql(关键步骤)在php编译的时候，我们加了如下的参数才可以实现关联Mysql(此处目的只是列出来与mysql有关联的扩展，上面编译时已包含进来了)：因为php7.0以上的版本废弃了mysql扩展，所以我们使用mysqli和pdo_mysql来实现关联Mysql。\n--with-mysqli \\\n--with-pdo-mysql \\\n--enable-mysqlnd\n其实，在编译的时候我们就已经添加了关联Mysql的依赖了(最好在之前就弄了，不然会挺麻烦的)。若忘记在编译的时候加上上诉依赖模块，可以使用如下方法来添加扩展，此处以添加mysqli扩展为例。\nphp配置文件中默认扩展的存放位置为***/usr/local/php7/lib/php/extensions/no-debug-zts-20160303***\n1.在解压出来的php-7.1.26中查找是否包含mysqli这扩展文件\ncd &#x2F;usr&#x2F;local&#x2F;php-7.1.26&#x2F;ext&#x2F;\n#使用ls查看文件夹内容\nls\n#若无，则需要在网上下载相应的扩展压缩包，之后再进入解压出来的文件夹内执行以下步骤的操作(不包括cd #mysqli)若有mysqli，则可以直接在该文件夹下编译安装该扩展，步骤如下\ncd mysqli\n#使用phpize初始化，若在初始化时出错，报错信息为Cannot find autoconf。。。。。则可以使用\n#yum install autoconf来解决\n&#x2F;usr&#x2F;local&#x2F;php7&#x2F;bin&#x2F;phpize\n#编译\n.&#x2F;configure \n#安装\nmake &amp;&amp; make install\n#安装完成会在默认扩展存放路径中生成mysqli.so文件\n2.编辑php.ini\n#cd到相应路径下\ncd &#x2F;usr&#x2F;local&#x2F;php7&#x2F;lib\n#开启编辑\nvim php.ini\n#引入扩展\nextension&#x3D;mysqli.so\n#重启php，步骤如之前重启php-fpm所示一致\n3.在之前测试访问的info.php中，若出现如下两个图中的mysqli和pdo_mysql扩展，则说明关联mysql成功了\n\n \n第五步：(测试用例)LINUX下的ECShop部署1.将ECShop的源代码appserver和ecshop放到我们安装的Apache的htdocs文件夹中，\n#htdocs的路径如下\ncd &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs&#x2F;\n#给两个文件夹赋予读、写和可执行的权限\nchmod -R 777 appserver\nchmod -R 777 ecshop\n2.在浏览器中输入ip/ecshop就可以看到安装向导页面啦（1图）！(之前安装的时候都踩了好多坑，2图所示，原因就是文件夹的权限没有给，给这两个文件夹可读可写的权限后就可以正常安装ecshop啦)\n\n\n同时，还遇到的一个坑是数据库连接不上，原因是我使用的是阿里云服务器，而localhost不知道为什么解析不了，输入服务器的具体ip地址就可以成功连接了。\n参考PHP7安装：https://www.jianshu.com/p/4438ff8aa44a\nLinux下的EC_Shop部署：https://blog.csdn.net/iteye_14593/article/details/82675082\n","slug":"LAMP环境搭建","date":"2019-04-06T06:52:46.000Z","categories_index":"Linux","tags_index":"LAMP","author_index":"安安哎呀呀"},{"id":"09e2399cbd512aa4be49b295beddf488","title":"Springboot整合redis","content":"####一、redis服务器安装与配置1.redis安装\n#下载相应相应的tar.gz包\nwget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-5.0.3.tar.gz\n#解压\ntar -zxvf redis-5.0.3.tar.gz\n#到解压出来的目录下执行编译与安装\ncd redis-5.0.3\nmake \n#安装至&#x2F;usr&#x2F;local&#x2F;redis这个文件夹底下\nmake install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis\n#若执行了上一步的指定相应目录，可以将redis.conf也移过去，方便启动的时候使用，其实也可以不在那位置，我们可以在启动的时候指定想要使用的配置文件\n2.开启远程访问redis服务：修改redis.conf配置文件，修改部分如下：\n1)注释掉bind 127.0.0.1\n2)redis在目前的版本中单纯注释上一步的内容还是不行的，需要将protected-mode yes改为protected-mode no\n3)若服务器开启了防火墙的话，需要开放6379这个端口号，开放端口号指令如下：\nfirewall-cmd --zone&#x3D;public --add-port&#x3D;6379&#x2F;tcp --permanent\n4)重新加载firewalld：\nfirewall-cmd --reload\n3.后台启动redis、关闭redis\n1)需要修改redis.conf文件中的daemonize no 的no改为daemonize yes;\n&#x2F;&#x2F;其中后面的.&#x2F;etc&#x2F;redis.conf为加载配置文件\n2)进入redis目录下执行  bin&#x2F;redis-server  .&#x2F;etc&#x2F;redis.conf  开始后端执行redis\n3)执行 ps -ef | grep -i redis 来查看redis运行的进程号\n&#x2F;&#x2F;若要关闭redis服务，可执行如下指令\n4)bin&#x2F;redis-cli shutdown\n####二、springboot整合redis1.引入依赖包:\n&lt;!-- https:&#x2F;&#x2F;mvnrepository.com&#x2F;artifact&#x2F;org.springframework.boot&#x2F;spring-boot-starter-data-redis --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;&#x2F;artifactId&gt;\n        &lt;&#x2F;dependency&gt;\n2.配置application.yml中配置redis:\nspring:\n  redis: \n    host: localhost\n    port: 6379\n    password:          # redis默认不使用密码，即空。若有，输入对应密码即可\n    database: 0\n    pool:\n      max-active: 8   # 连接池最大连接数(-1表示无没有限制)\n      min-idle: 0     # 连接池中最小空闲连接\n      max-idle: 8     # 连接池最大空闲连接\n      max-wait: -1    # 连接池最大阻塞时间(-1表示无没有限制)\n3.在springboot启动类上加上注解@EnableCaching，如下图：4.创建RedisUtil.java类：\npackage com.spring.boot.demo.Util;\n\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.stereotype.Component;\n\nimport javax.annotation.Resource;\nimport java.util.concurrent.TimeUnit;\n\n&#x2F;**\n * @Author: JerryLiang\n * @Date: 2019&#x2F;3&#x2F;20 21:33\n **&#x2F;\n@Component\npublic class RedisUtil &#123;\n\n    @Resource\n    private RedisTemplate&lt;String, Object&gt; redisTemplate;\n\n    public void setRedisTemplate(RedisTemplate&lt;String, Object&gt; redisTemplate)&#123;\n        this.redisTemplate &#x3D; redisTemplate;\n    &#125;\n\n    &#x2F;**\n     * 指定缓存失效时间\n     * @param key 键\n     * @param time 时间(秒)\n     *&#x2F;\n    public boolean expire(String key, long time) &#123;\n        try&#123;\n            if(time &gt; 0)&#123;\n                redisTemplate.expire(key, time, TimeUnit.SECONDS);\n            &#125;\n            return true;\n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n &#x2F;**\n     * 普通缓存获取\n     *\n     * @param key 键\n     * @return 值\n     *&#x2F;\n    public Object get(String key) &#123;\n        return key &#x3D;&#x3D; null ? null : redisTemplate.opsForValue().get(key);\n    &#125;\n\n    &#x2F;**\n     *  判断key是否存在\n     * @param key 键\n     * @return true 存在 false 不存在\n     *&#x2F;\n    public boolean hasKey(String key)&#123;\n        try&#123;\n            System.out.println(key);\n            return redisTemplate.hasKey(key);\n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     *  删除缓存\n     * @param key\n     *&#x2F;\n    @SuppressWarnings(&quot;unchecked&quot;)\n    public boolean del(String key)&#123;\n        if (key.equals(&quot;&quot;)|| key&#x3D;&#x3D;null) &#123;\n            return false;\n        &#125;else&#123;\n            redisTemplate.delete(key);\n            return true;\n        &#125;\n    &#125;\n\n    &#x2F;**\n     * 普通缓存放入\n     *\n     * @param key   键\n     * @param value 值\n     * @return true成功 false失败\n     *&#x2F;\n    public boolean set(String key, String value) &#123;\n        try &#123;\n            System.out.println(key);\n            redisTemplate.opsForValue().set(key, value);\n            return true;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n\n    &#125;\n\n    &#x2F;**\n     * 普通缓存放入并设置时间\n     *\n     * @param key   键\n     * @param value 值\n     * @param time  时间(秒) time要大于0 如果time小于等于0 将设置无限期\n     * @return true成功 false 失败\n     *&#x2F;\n    public boolean set(String key, String value, long time) &#123;\n        try &#123;\n            if (time &gt; 0) &#123;\n                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);\n            &#125; else &#123;\n                set(key, value);\n            &#125;\n            return true;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n            return false;\n        &#125;\n    &#125;\n\n\n&#125;\n\n5.在需要使用RedisUtil的类中注入RedisUtil：\n@Autowired\nprivate RedisUtil redisUtil;\n6.测试使用：\nredisUtil.set(&quot;jerry&quot;,&quot;liang&quot;);\n7.查看redis：\n","slug":"Springboot整合redis","date":"2019-03-21T06:52:34.000Z","categories_index":"Java","tags_index":"redis,springboot","author_index":"安安哎呀呀"},{"id":"d8b4487bc85f218a66607245054b2ebc","title":"Nginx详解","content":"nginx详解一、什么是正向代理和反向代理？\n\n正向代理\n   \n\n  反向代理\n\n    \n\n\nURI、URL和URN:\n\n  URI ：Uniform Resource Identifier，统一资源标识符；\n\n  URL：Uniform Resource Locator，统一资源定位符；\n\n  URN：Uniform Resource Name，统一资源名称。\n\n\n  \n\n  URL主要由三部分组成：第一部分是协议(或成为服务方式)，第二部分是存有该资源的主机IP地址(有时也包括端口号)，第三部分是主机资源的具体地址，如目录和文件夹名等。\n\n  URI和URL都定义了资源是什么，但URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。\n\n\n二、nginx负载均衡策略\nnginx服务器负载均衡策略可以划分为两大类：\n1.内置策略\n\n  轮询：将每个前端请求按顺序（时间顺序或者排列顺序）逐一分配到不同的后端节点上，对于出现问题的后端节点自动排除；\n\n  加权轮询：在轮询的基础上加上weight，指定各后端节点被轮询到的几率；\n\n  IP_hash：将前端访问的IP进行hash操作，然后根据hash结果将请求分配给不同的后端节点上。注：同一IP经过hash的出来的值是一样的，即请求固定落在hash后选择的那台后端服务器上。\n\n\n2.扩展策略\n\n  url_hash：对前端访问的url进行hash操作。（若后端服务器异常，不能自动排除该节点）\n\n  fair：将请求转发到一个最近负载最小的后台节点。如何判断负载最小？Nginx通过后端节点对请求的响应时间来判断负载的情况。响应时间短的节点负载相对较轻。\n\n\n三、nginx基本配置详解\n##### **1.nginx.conf**:\n\nworker_processes 1;\nerror_log  &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx_error.log;\npid &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;nginx.pid;\nevents&#123;\n worker_connections 1024;\n&#125;\n​\nhttp&#123;\n include mime.types;\n default_type application&#x2F;octet-stream;\n\n sendfile on;\n keepalive_timeout 65;\n\n upstream  back&#123;\n server address weight&#x3D;2 max_fails&#x3D;5 fail_timeout&#x3D;30s;\n server address weight&#x3D;1 max_fails&#x3D;5 fail_timeout&#x3D;30s;\n ip_hash;\n &#125;\n\n server&#123;\n listen 80;\n server_name localhost;\n\n location &#x2F; &#123;\n index index.html index.php;\n root &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html;\n &#125;\n\n location ~ &#x2F;api&#x2F;1.0&#x2F;ll&#x2F;(.*) &#123;\n proxy_pass http:&#x2F;&#x2F;back; # 设置被代理服务器地址\n proxy_set_header Host $host;\n proxy_set_header X-Real-IP $remote_addr;\n proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n &#125;\n\n error_page 404      &#x2F;404.html;\n error_page 500 502 503 504 &#x2F;50x.html;\n location &#x3D; &#x2F;50x.html&#123;\n root html;\n &#125;\n &#125;\n\n&#125;\n\n2.upstream 中server指令语法如下：server address [parameters] 注： 关键字server为必选项，address也为必选项，可以是主机名、域名、ip或  unix socket，也可以指定端口号；  ​  parameters是可选参数，可以是如下参数：\n\n  down：将server标记为宕机状态；\n\n  backup：将组内服务器标记为备用服务器，只有当正常的服务器处于宕机状态或则繁忙状态时，该服务器才会被用来处理客户端请求；\n\n  weight：表示server的负载权重，权重越大被请求的几率越大，默认为1；\n\n  fail_timeout：请求时间超过这个值时，认定其为请求失败，此时断开连接，默认值为10s；\n\n  max_fails：设置一个请求失败的次数，在一定范围时间内（即fail_timeout时间内），当对组内某台服务器请求失败的次数超过该变量设置的值时，认为该服务器无效，默认值是1(即默认情况下只要发生错误就认为server宕机了)；\n\n  fail_timeout和max_fails通常联合使用：如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为该server已经宕机，从而在fail_timeout时间内不会再去请求这台server。\n3.location用法：location 模式| 含义\n\n\n—|—以 = 开头|表示精准匹配，如只匹配根目录结尾的请求，后面不能带任何字符串以 ^~ 开头|表示uri以某个常规字符串开头，不是正则匹配以 ~ 开头|表示区分大小写的正则匹配以 ~* 开头|表示不区分大小写的正则匹配以 / 开头|通用匹配, 如果没有其它匹配,任何请求都会匹配到\n 1)精准匹配 /，主机名后面不能带任何字符串\nlocation &#x3D; &#x2F; &#123;\n      [configuration A]\n&#125;\n2)通用匹配，所有地址都以/开头，所以这条规则将会在最后匹配，即默认请求\n location &#x2F; &#123;\n    [configuration B]\n&#125;\n3)匹配以 /test/ 开头的地址，匹配符合以后，还要继续往下搜索。只有后面的正则表达式没有匹配到时，这一条才会采用（该普通匹配遵循最长匹配规则），即若uri为/test/mine/则会采用第二条的配置\nlocation &#x2F;test&#x2F; &#123;\n  [configuration C]\n&#125;\nlocation &#x2F;test&#x2F;mine&#x2F; &#123;\n #配置\n&#125;\n4)匹配任何以/images/开头的地址，匹配符合以后，停止往下搜索正则\nlocation ^~ &#x2F;images&#x2F; &#123;\n  [configuration D]\n&#125;\n5)匹配所有以gif、jpg或jpeg结尾的请求。需要注意的是，若配置了4中的配置，则/images/下的图片都只会被配置D处理，因为^~不再往下搜索\nlocation ~* \\.(gif|jpg|jpeg)$ &#123;\n  [configuration E]\n&#125;\n6）各匹配顺序优先级如下\n(location &#x3D;) &gt; (location 完整路径) &gt; (location ^~ 路径)&gt; (location ~,~*正则顺序) &gt; (location 部分起始路径) &gt; (&#x2F;)\n7)测试时的configuration推荐使用以下配置来测试，可以配置不同的rewrite网址来达到测试效果,如下所示。在浏览器中输入ip+端口号/test/即可测试匹配是否成功。\nlocation &#x2F;test&#x2F; &#123;\n   rewrite ^ https:&#x2F;&#x2F;jeryliang.github.io&#x2F;;\n&#125;\n8)若使用location来实现访问静态文件的话，有以下需要注意的地方\n例：该例子就是访问nginx默认的index.html\n默认配置为：\nlocation &#x2F; &#123;\nindex index.html;\nroot &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html;\n&#125;\n修改后的配置：\nlocation &#x2F;html&#x2F; &#123;\n index index.html;\n root &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;; \n&#125;\n\n以上两个配置都能实现访问nginx默认的index.html。这是为什么呢？修改后的配置通过请求ip:port/html/也可以访问，是因为匹配字符串html会和root指定路径进行拼接，实际的拼接后的路径为/usr/local/nginx/html。而默认的其实也是拼接的，只不过匹配字符串为/，拼接后和原始/usr/local/nginx/html是一样的，所以访问到了index.html。\n4.nginx中的rewrite实现域名跳转在开始讲述rewrite功能前，需要搞清楚”地址重写”和”地址转发”两个概念。（注：rewrite功能依赖于PCRE库）\n\n  地址重写：其实也就是地址重定向，例：输入google.cn访问谷歌时，在被服务器重定向为www.google.com的过程就是地址重定向的过程，此时浏览器的地址会变为www.google.com；\n\n  地址转发：是指一个域名指指到另一个已有站点的过程。\n\n\n这两者的主要区别如下：\n\n  地址转发后客户端浏览器地址栏中的地址是不会改变的，而地址重写后的客户端浏览器地址栏中的地址改变为服务器选择确定的地址；\n\n  在一次地址转发过程中，只产生一次网络请求，而地址重写一般会产生两次或两次以上的请求；\n\n  地址转发的速度比地址重定向快。\n\n\nrewrite可以在server块或者location块中配置，以下为几个例子：\n# 例1：域名跳转\nserver &#123;\n listen 80;\n server_name liang.jerry.com;\n rewrite ^&#x2F; http:&#x2F;&#x2F;www.jerry.info&#x2F;;\n&#125;\n# 例2：多域名跳转\nserver &#123;\n listen 80;\n server_name  liang.jerry.name  liang.jerry.info;\n index index.htm index.php;\n root &#x2F;usr&#x2F;local&#x2F;html;\n if($host  ~ jerry\\.info)&#123;    # $host的值中是否包含(其中~对大小写敏感)jerry.info字符串，若                             #包含则为真\n rewrite ^(.*) http:&#x2F;&#x2F;liang.jerry.name&#x2F;$1 permanent; \n #^为匹配字符串的开始，（.*）匹配任意字符，permanent表示返回301永久重定向，地址栏会显示跳转后的地址；\n &#125;\n&#125;\n# 例3：三级域名跳转\nserver &#123;\n listen 80;\n server_name liang1.jerry.name liang2.jerry.name;\n # ~*对字母大小写不敏感，若$http_host中包含 任意字符.jerry.name字符串，则为真\n if($host ~*  ^(.*)\\.jerry\\.name$)&#123;\n rewrite ^(.*) http:&#x2F;&#x2F;liang.jerry.name$1;\n break; # 此处break目的在于重定向后不再进行location的匹配（即后续的其他rewrite），\n &#125;\n&#125;\n\n\n5.rewrite常用正则.  匹配除换行符以外的任意字符\n？ 重复0次或1次\n+  重复1次或更多次\n*  重复0次或更多次\n\\d 匹配数字\n^  匹配字符串的开始\n$  匹配字符串的结束\n&#123;n&#125; 重复n次\n&#123;n,&#125; 重复n次或更多次\n[c]  匹配单个字符c\n[a-z] 匹配a-z小写字母的任意一个\n小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容，同时还有转义字符\\\n\n5.反向代理服务需要注意的细节proxy_pass指令，先看如下例子：\n# 例1\nupstream  proxy_svrs &#123;\n server http:&#x2F;&#x2F;192.168.1.1:8088&#x2F;uri&#x2F;;\n server http:&#x2F;&#x2F;192.168.1.1:8088&#x2F;uri&#x2F;;\n server http:&#x2F;&#x2F;192.168.1.1:8088&#x2F;uri&#x2F;;\n&#125;\nserver &#123;\n listen 80;\n server_name www.jerry.com;\n location &#x2F; &#123;\n proxy_pass  proxy_svrs;\n &#125;\n&#125;\n# 例2\nupstream proxy_svrs &#123;\n server 192.168.1.1:8088&#x2F;uri&#x2F;;\n server 192.168.1.1:8088&#x2F;uri&#x2F;;\n server 192.168.1.1:8088&#x2F;uri&#x2F;;\n&#125;\nserver &#123;\n listen 80;\n server_name www.jerry.com;\n location &#x2F; &#123;\n proxy_pass  http:&#x2F;&#x2F;proxy_svrs;\n &#125;\n&#125;\n\n即在服务器组中已经指明了传输协议”http://“时，proxy_pass中就不需要指明，反之，要在proxy_pass中指明。\n需要注意的是如下的情况：\nserver proxy_svrs &#123;\n listen 80;\n server_name www.jerry.com;\n location &#x2F;server&#x2F; &#123;\n proxy_pass http:&#x2F;&#x2F;192.168.1.2&#x2F;jerry&#x2F;;\n &#125;\n&#125;\n\n在这配置的情况下，假如客户端发起的请求为http://www.jerry.com/server/，Nginx会把地址转向”http://192.168.1.2/jerry/“。所以，在使用proxy_pass代理的时候，如果不想改变原有地址中的URI，就不要在URL中配置URI。同时，需要注意的是”/“同样是作为URI，如http://192.168.1.2和http://182.168.1.2/是有区别的，若代理的URL中包含URI，第二种会替换掉原有URL中的URI。如下：\nserver &#123;\n listen 80;\n server_name www.jerry.com;\n location &#x2F;server&#x2F; &#123;\n # 配置1:   proxy_pass  http:&#x2F;&#x2F;192.168.1.2;\n # 配置2:   proxy_pass  http:&#x2F;&#x2F;192.168.1.2&#x2F;;\n &#125;\n&#125;\n\nproxy_set_header指令\n该指令可以更改Nginx服务器接收到的客户端请求的请求头信息，然后将新的请求头发送给被代理的服务器。其语法结构为：\nproxy_set_header field value；\n# field为要更改的信息所在的头域；\n# value为更改的值，支持使用文本、变量或者变量的组合\n#例1\nproxy_set_header Host $http_host; #将目前Host头域的值填充成客户端的地址\nproxy_set_header Host $host; #将当前location块的server_name指令值填充到Host头域\n\nproxy_http_version指令\n该指令用于设置Nginx服务器提供代理服务的HTTP协议版本，默认设置为1.0版本。1.1版本支持upstream服务器组设置中的keepalive指令。\nproxy_http_version 1.0  | 1.1;\n参考\n  location、rewrite规则：https://www.cnblogs.com/dadonggg/p/7797281.html\n\n  《nginx高性能web服务器详解》\n\n\n","slug":"Nginx详解","date":"2019-03-19T06:52:16.000Z","categories_index":"Devops","tags_index":"Nginx","author_index":"安安哎呀呀"},{"id":"aaca0be6401ddc4b6b987223429803e8","title":"Springboot超详细搭建过程","content":"一、创建篇\n新建项目，如下图所示。\n  \n\n选择Spring Initializr。\n \n\n填写Group、Artifact和Name后点击next，如下图所示。\n \n\n 选择需要的组件：基本组件有web模块中的web和web server、SQL模块中的MySQL、JDBC和Mybatis、额外的组件可以根据需求自行选择，不过需要注意的是springboot版本不要选择太高，此处选择的是1.5.19版本。\n\n\n\n5.确定项目名和项目存储路径。\n\n6.点击finish，整个项目架构如下图所示。其中(项目名+Application).class为sprinboot核心类、application.properties为主配置文件。\n\n二、配置篇1.连接数据库配置(因为我们已经在选择组件中选择了SQL和JDBC)所以不需要手动引入Maven依赖，只需要直接配置就好），(.yml)和(.properties)的配置格式是不一样的，我个人比较喜欢使用yml格式的，因此我将application.properties改为了application.yml。\n\n将properties后缀名改为yml，点击refactor即可完成修改。\n\n具体配置如下，(注：yml配置格式相对教严格，需要注意以下各内容的具体位置)\n \ndriver-class-name为数据库连接驱动，username和password为填写自己想要连接的数据库用户名和密码，url中的spring为我本地中的一个数据库，使用utf-8编码格式，不开启ssl验证。\n2.在startProject\\src\\main\\java\\com.test.demo中，创建MVC模式对应的package，如下\n\ndomain包主要用来集中管理相应的实体类，controller为控制层，service和serviceImpl分别为服务层和服务实现层，mapper用来管理的是与mybatis结合后存储的接口类，类似于传统的dao层。\n3.在startProject\\src\\main\\resources中，创建mapperXml，存放mapper对应的mapper.xml文件。\n \n4.配置项目端口号和配置定位mybatis的mapperXml路径。其中开放的端口号设置为18099(可自行指定端口，但是不可与其他开放的端口有冲突，不指定时默认为8080端口)。mapper-location指定了扫描mapperXml中的所有以xml为后缀名的文件。\n\n三、测试篇1.在domain包中创建实体类User.class。属性自定义，与数据库中表对应属性即可。\n2.在controller包中创建UserController类。\n\n3.在UserController中编写如下代码。注解@RequestMapping中的value值可以自定义，其为请求该接口的一个url。第一个@RequestMapping为类级别，第二个@RequestMapping为方法级别。如我们需请求该接口，具体如下即可调用该方法：localhost:18099/user/login。\n \n4.在service中创建UserService接口。\n\n \n输入名字UserService，选择Interface，点击OK即可完成创建。\n5.在serviceImpl中创建UserServiceImpl实现类，实现UserService。加入注解@Service并implements UserService。\n!\n6.在mapper中创建UserMapper接口，创建方法与第4步一致。并加入注解@Repository。\n\n7.在resource下的mapperXml中创建UserMapper.xml文件。过程如下图所示，因未找到具体的xml创建，所以可以选择圈出的3个红圈中的任意一个，一会直接修改后缀名，并将如下代码复制覆盖文件内容即可。\n\n代码如下(注：namespace中的com.test.demo.mapper.UserMapper需要关联的Mapper的具体路径和名字。此处意思即为：该xml关联的是UserMapper)。\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;\n&lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Mapper 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot; &gt;\n&lt;mapper namespace&#x3D;&quot;com.test.demo.mapper.UserMapper&quot;&gt;\n&lt;&#x2F;mapper&gt;\n\n8.在UserController中注入UserService。使用注解@Autowired自动注入。\n9.调用Service层的getUserById()方法，根据UserId来进行查询，并输出结果。因为我的UserService中还未创建getUserById()方法，所以我们要到UserService中创建该方法，如第10步所示。\n\n我在User实体类中生成了getter和setter方法，并重写了toString方法，以便查看属性值。\n\n10.在UserService中编写接口方法getUserById()。\n\n11.在UserServiceImpl中注入UserMapper并实现该方法。\n\n12.上一步中是返回UserMapper中的getUserById方法返回的结果，因此要在UserMapper中编写该方法。\n\n13.在UserMapper中实现查询，即getUserById。这里涉及的是有关mybatis的相关知识，可参考如下链接：\nhttps://www.jianshu.com/p/48141abd6a5a\n \n代码如下：\n&lt;resultMap id&#x3D;&quot;userList&quot; type&#x3D;&quot;com.test.demo.domain.User&quot;&gt;\n &lt;id column&#x3D;&quot;id&quot; property&#x3D;&quot;id&quot; jdbcType&#x3D;&quot;INTEGER&quot;&#x2F;&gt;\n &lt;result column&#x3D;&quot;username&quot; property&#x3D;&quot;username&quot; jdbcType&#x3D;&quot;VARCHAR&quot;&#x2F;&gt;\n &lt;result column&#x3D;&quot;password&quot; property&#x3D;&quot;password&quot; jdbcType&#x3D;&quot;VARCHAR&quot;&#x2F;&gt;\n &lt;result column&#x3D;&quot;note&quot; property&#x3D;&quot;note&quot; jdbcType&#x3D;&quot;VARCHAR&quot;&#x2F;&gt;\n &lt;&#x2F;resultMap&gt;\n &lt;select id&#x3D;&quot;getUserById&quot; parameterType&#x3D;&quot;int&quot; resultMap&#x3D;&quot;userList&quot;&gt;\n SELECT * FROM t_user WHERE id &#x3D; #&#123;id&#125;\n &lt;&#x2F;select&gt;\n14.在核心类中（即项目名+application）中，添加扫描mapper包，即mapper的路径。\n\n15.至此，整个配置就配置完了，我们开始启动项目进行测试吧！如下为启动成功的界面。\n\n开始使用postman测试。输入url:localhost18099/user/login。点击send。\n \n可以看到控制台输出的结果，大功告成。\n\n","slug":"Springboot超详细搭建过程","date":"2019-03-17T07:00:41.000Z","categories_index":"Java","tags_index":"springboot","author_index":"安安哎呀呀"},{"id":"03262ebd7a1c2d262927581eaf4e7b3b","title":"Jenkins持续集成","content":" \n什么是Jenkins？\nJenkins是一个开源的、提供友好操作界面的持续集成(CI)工具，起源于Hudson（Hudson是商用的），主要用于持续、自动的构建测试软件项目、监控外部任务的运行（这个比较抽象，暂且写上，不做解释）。Jenkins用Java语言编写，可在Tomcat等流行的servlet容器中运行，也可独立运行。  通常与版本管理工具(SCM)、构建工具结合使用；常用的版本控制工具有SVN、GIT，构建工具有Maven、Ant、Gradle。\nJenkins两大特性\n1.持续集成（Continuous integration, CI）\n \n持续集成是一种软件开发实践，即团队开发成员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试)来验证，从而尽快地发现集成错误。许多团队发现这个过程可以大大减少集成的问题，让团队能够更快的开发内聚的软件。\n持续集成有以下几个优点：\n\n  从检出代码、编译构建、运行测试、结果记录、测试统计等都是自动完成的，减少人工干预；\n\n  任何时间、任何地点生成可部署的软件，出现问题，项目成员会被马上通知到，问题第一时间修复；\n\n  增强项目可见性，有效的控制台日志能帮助我们更好的解决存在的问题。\n\n\n2.持续交付（Continuous delivery, CD）\n持续交付则是经典的敏捷的软件开发方法的自然延伸，它强调产品在修改后到部署上线的流程要敏捷话、自动化。甚至一些较小的改变也要尽早的部署上线。通俗的讲可以有几个特点：\n\n  代码越早交付出去，用户越早能用到，快就是商业价值；\n\n  用户反馈能及时作出处理，能帮助产品市场人员调整测策略；\n\n  降低修改成本。\n\n\n \n前后对比\n1.传统的项目部署\n \n2.持续部署\n \nJekins的安装\n官方下载地址：https://jenkins.io/download/\n \n我选择下载的war包，将war包用xftps传到自己的服务器后有两种方式可以启动jenkins：\n第一种：  ​  将war包移至tomcat/webapps下，启动tomcat  ​  浏览器输入: 你的IP地址:tomcat开放的端口号\n第二种：\n进入你war包存放的位置，输入以下指令后台启动jenkins：\nnohup java -jar jenkins.war --logfile=server.log --httpPort=8088 &gt; server.log 2&gt;&amp; 1 &amp; \n默认情况不指定--httpPort的话jenkins使用的是8080端口，在此我指定的端口是8088\nJenkins的配置\n以下为Jenkins的主界面：\n \n其中主要的配置都是在系统管理中设置：\n\n  在系统设置里设置全局设置相关的内容；\n\n  在全局安全配置里配置各用户权限；\n\n  在全局工具里配置相应的项目运行环境，比如JDK，MAVEN等；\n\n  在插件管理中添加自己想要使用的插件；\n\n  在节点管理中管理自己的服务器集群。\n\n\n \n全局工具配置\n \n配置JDK、Git、Maven等路径。\n插件管理\n \n在插件管理中插件类型众多，很大程度的满足了我们的需求，可以选择自己需要使用的插件，也可以制作相应的插件上传。\n常用的插件： \n主要介绍以下几个插件：\nGitHub Branch Source Plugin ：代码仓库；\nDeploy to container Plugin ：部署代码至相应的容器；\nMaven Integration Plugin ：构建Maven项目需要使用此插件；\nSSH Plugin 和 SSH Slave Plugin ：配置免密登录某一节点需要使用到；\n节点管理\n \n新建项目\n \n选择需要怎样构建一个项目，在此以构建一个自由风格的软件项目为例。\n源码管理\n \n设置仓库url，构建时从此仓库获得源码。这里不仅可以使用Git源码管理，同样可以使用SVN，Coding等别的仓库，需要下载相应的插件。\n构建触发器\n构建触发器是指以何种方式来触发自动构建：\n\n  第一种：触发远程构建（例如，使用脚本）\n\n \n图中的身份证令牌（TOKEN_NAME）即为要触发构建需要的KEY，访问URL中加入key后才可自动触发自动构建。\n\n  第二种：在其他工程构建后触发；\n\n  第三种：定时构建；\n\n  第四种：GitHub hook trigger for GITScm polling，使用github上的webhook钩子来实现代码push时，发送相应的请求，该请求即为我们触发自动构建的URL加key;\n\n  第五种：轮询SCM，\n\n\n构建\n此处选择的是执行相应的shell命令：\n \nBUILD_ID&#x3D;DONTKILLME\n. &#x2F;etc&#x2F;profile\nexport PROJ_PATH&#x3D;pwd\nexport TOMCAT_APP_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;apache-tomcat-8.5.34\n\nsh $PROJ_PATH&#x2F;order&#x2F;deploy.sh\n其中前四句指令是在/etc/profile/路径下添加PROJ_PATH（项目路径）的环境配置，TOMVAT_APP_PATH（tomcat路径），最后一个是执行项目中的脚本。\n","slug":"Jenkins持续集成","date":"2018-11-24T07:56:32.000Z","categories_index":"Devops","tags_index":"CI","author_index":"安安哎呀呀"},{"id":"54e1d69dbe01003cc0c2e45b21bc6b3e","title":"Mybatis","content":"一.Mybatis1.Hibernate全表映射，而Mybatis半自动映射且可配置动态SQL\n2.Mapper 是一个接口，而没有任何实现类，它的作用是发送SQL，然后返回我们需要的结果，或者执行SQL从而修改数据库的数据。\n3.Mybatis别名（typeAliases）不区分大小写；\n4.typeHandler自定义类型转换器；\n二.映射器1.首先定义映射器接口（方法调用的地方），其次给出XML文件（SQL语句书写的地方），最后引入映射器，引入映射器的方法有如下几种，假设roleMapper.xml 在mapper 这个包下，接口类为RoleMapper 同样接口类也在mapper 这个包下：\n1)用文件路径引入映射器，\n&lt;mappers&gt;\n &lt;mapper resource&#x3D;&quot;mapper&#x2F;roleMapper.xml&quot;&#x2F;&gt;\n&lt;&#x2F;mappers&gt;\n2)用包名引入映射器，\n&lt;mappers&gt;\n &lt;mapper resource&#x3D;&quot;mapper&#x2F;&gt;\n&lt;&#x2F;mappers&gt;\n3)用类注册器引入映射器，\n&lt;mappers&gt;\n &lt;mapper resource&#x3D;&quot;mapper&#x2F;RoleMapper&quot;&#x2F;&gt;\n&lt;&#x2F;mappers&gt;\n4)用别的xml配置文件引入映射器，\n&lt;mappers&gt;\n &lt;mapper url&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;mapper&#x2F;roleMapper&quot;&gt;\n&lt;&#x2F;mappers&gt;\n2.在映射器中可以定义的元素名称如下：\n\n\nselect中的元素resultType 和resultMap不能同时使用；\n3.自动映射 autoMappingBehavior\n这个参数，当它不设置为NONE时，Mybatis会提供自动映射功能，只要返回的SQL列明和JavaBean的属性一致，Mybatis就会帮助我们回填这些字段而无需任何配置。自动映射可以在配置文件中的setting元素中配置 autoMappingBehavior属性来设置其策略：\n1）NONE，取消自动映射；\n2）PARTIAL，只会自动映射，没有定义嵌套结果集映射的结果集(没设置该属性时这个属性为默认值)；\n3）FULL，会自动映射任意复杂的结果集（无论是否嵌套）。\n4.sql元素\n\nsql元素的主要作用是避免多次查询的时候重复写字段名，通过设置上图所示代码段来定义查询的字段，其中id属性是为了在select语句中引用该元素。标签引用sql元素，refid属性的值对应要引用的sql元素的id名。\n5.resultMap\nresultMap元素中的id元素是表示哪个列是主键。\n6.级联\n级联中存在三种对应关系：一对一、一对多和多对多的关系。\n1）association一对一级联：\n&lt;resultMap id&#x3D;&quot;&quot; type&#x3D;&quot;&quot;&gt;\n ....\n &lt;association property&#x3D;&quot;&quot; colum&#x3D;&quot;&quot; select&#x3D;&quot;&quot;&gt;\n ....\n&lt;&#x2F;resultMap&gt;\n注：级联即在经过一次select语句后返回结果后再调用一次resultMap中相应的select语句，其中association属性中的property为当前类的某个属性值 ， colum为直指定传递给select语句的参数，select中对应的为另一个select的路径与id，若调用的为当前Mapper下的select则直接值为id，若为另一个Mapper的则要给出路径与id。\n2）collection一对多级联：\ncollection的属性值设置与association的一致，都有property、colum和select。\n3）discriminator鉴别级级联：\n&lt;resultMap id&#x3D;&quot;&quot; type&#x3D;&quot;&quot;&gt;\n ....\n &lt;discriminator javaType&#x3D;&quot;&quot; colum&#x3D;&quot;&quot; &gt;\n &lt;case value&#x3D;&quot;&quot; resultMap&#x3D;&quot;&quot;&#x2F;&gt;\n &lt;case value&#x3D;&quot;&quot; resultMap&#x3D;&quot;&quot;&#x2F;&gt;\n &lt;&#x2F;discriminator&gt;\n ....\n&lt;&#x2F;resultMap&gt;\n三.动态SQLMyBatis的动态SQL包括以下几种元素：\n\n1.if元素示例如下，其中接收参数时判定其是否为空应该用**_paremeter** 而不是用传入的参数名（如本例传入的roleName判空时应该用_parameter进行代替,而不是roleName，是因为我们接收参数的parameterType=”string”类型，而不是javaBean）\n&lt;select id&#x3D;&quot;findRole&quot; parameterType&#x3D;&quot;String&quot; resultMap&#x3D;&quot;roleMap&quot;&gt;\n select *from t_role where 1&#x3D;1\n &lt;if test&#x3D;&quot;_parameter !&#x3D;null &quot;&gt;\n and role_name like concat(&#39;%&#39;,#&#123;roleName&#125;,&#39;%&#39;)\n &lt;&#x2F;if&gt;\n &lt;&#x2F;select&gt;\n2.choose、when、otherwise元素\n以上三种元素类似于switch….case….default 语句，parameter=”role” ,role 是一个javaBean ，所以判段为不为空时可以直接使用属性名判定（如下）where元素的条件：\n&lt;select id&#x3D;&quot;findRole&quot; parameterType&#x3D;&quot;role&quot; resultMap&#x3D;&quot;roleMap&quot;&gt;\nselect *from t_role where 1&#x3D;1\n&lt;choose&gt;\n&lt;when test&#x3D;&quot;roleNo !&#x3D; null and roleNo !&#x3D; &#39;&#39;&quot;&gt;\nand role_no &#x3D; #&#123;roleNo&#125;\n&lt;&#x2F;when&gt;\n&lt;when test&#x3D;&quot;roleName  !&#x3D; null and roleName !&#x3D;&#39;&#39;&quot;&gt;\nand role_name like concat(&#39;%&#39;,#&#123;roleName&#125;,&#39;%&#39;)\n&lt;&#x2F;when&gt;\n&lt;otherwise&gt;\nand note is not null\n&lt;&#x2F;otherwise&gt;\n&lt;&#x2F;choose&gt;\n&lt;&#x2F;select&gt;\n\ntrim 、where、 set 元素\n set元素的使用，可以更新全部，也可以更新部分值。\n&lt;update id&#x3D;&quot;updateRole&quot; parameterType&#x3D;&quot;role&quot;&gt;\n update t_role \n &lt;set&gt;\n &lt;if test&#x3D;&quot;roleName !&#x3D; null and roleName !&#x3D;&#39;&#39;&quot;&gt;\n role_name &#x3D; #&#123;roleName&#125;,\n &lt;&#x2F;if&gt;\n &lt;if test&#x3D;&quot;note!&#x3D;null and note !&#x3D; &#39;&#39;&quot;&gt;\n note &#x3D; #&#123;note&#125;\n &lt;&#x2F;if&gt;\n &lt;&#x2F;set&gt;\n where role_no &#x3D; #&#123;roleNo&#125;\n&lt;&#x2F;update&gt;\ntrim的prefix代表的是语句的前缀，而prefixOverrides代表的是你需要去掉的那种字符串。\n&lt;select id&#x3D;&quot;findRole&quot; parameterType&#x3D;&quot;role&quot; resultMap&#x3D;&quot;roleMap&quot;&gt;\nselect *from t_role \n&lt;trim prefix&#x3D;&quot;where&quot; prefixOverrides&#x3D;&quot;and&quot;&gt;\n&lt;if test&#x3D;&quot;roleName !&#x3D; null and roleName !&#x3D;&#39;&#39;&quot;&gt;\nand role_name like concat(&#39;%&#39;,#&#123;roleName&#125;,&#39;%&#39;)\n&lt;&#x2F;if&gt;\n&lt;&#x2F;trim&gt;\n&lt;&#x2F;select&gt;\nforeach元素\n\n\nforeach元素是一个循环语句，它的作用是遍历集合。(下例中的user为javaBean)\n&lt;select id&#x3D;&quot;findUserBySex&quot; resultType&#x3D;&quot;user&quot;&gt;\n select * from t_user where sex in\n &lt;foreach item&#x3D;&quot;sex&quot; index&#x3D;&quot;index&quot;  collection&#x3D;&quot;list&quot; open&#x3D;&quot;(&quot;  separator&#x3D;&quot;,&quot; close&#x3D;&quot;)&quot;&gt;\n #&#123;sex&#125;\n &lt;&#x2F;foreach&gt;\n&lt;&#x2F;select&gt;\n\n  collection 配置的sexList 是传递进来的参数名称，它可以是一个数组或者List、Set等集合；如果是list类型collection属性值需要为list ，如果是数组类型collection属性值为array,\n\n  item配置的是循环中当前元素别名；\n\n  index配置的是当前元素在集合的位置下标；\n\n  open和close配置的是以什么符号将这些集合元素包装起来；\n\n  separator 是各元素的间隔符。\n\n\n5.bin元素\nbin元素的作用是通过OGNL表达式去自定义一个上下文变量。（作用类似与mysql中的concat拼接模糊查找，但其同样可以在oracle数据库中使用，提高了可移植性）\n使用bin模糊查询(其中_parameter代表接收到的参数)：\n&lt;select id&#x3D;&quot;findRole&quot; resultType&#x3D;&quot;Role&quot;&gt;\n &lt;bind name&#x3D;&quot;pattern&quot; value&#x3D;&quot;&#39;%&#39;+_parameter+&#39;%&#39;&quot;&#x2F;&gt;\n SELECT * FROM t_role where role_name like #&#123;pattern&#125;\n&lt;&#x2F;select&gt;\n以上只是单个参数的绑定，下面我们举例绑定多个参数的模糊查询：\n&#x2F;&#x2F;mapper接口\npublic List&lt;RoleBean&gt; findRole (@Param(&quot;roleName&quot;)String roleName,@Param(&quot;note&quot;)String note);\n&#x2F;&#x2F;mapper.xml\n&lt;select id&#x3D;&quot;findRole&quot; resultType&#x3D;&quot;Role&quot;&gt;\n &lt;bind name&#x3D;&quot;pattern_roleName&quot; value&#x3D;&quot;&#39;%&#39;+roleName+&#39;%&#39;&quot;&#x2F;&gt;\n &lt;bind name&#x3D;&quot;pattern_note&quot; value&#x3D;&quot;&#39;%&#39;+note+&#39;%&#39;&quot;&#x2F;&gt;\n SELECT *FROM t_role where role_name like #&#123;pattern_roleName&#125;\n and note like #&#123;pattern_note&#125;\n&lt;&#x2F;select&gt;\n","slug":"Mybatis","date":"2018-11-24T07:00:52.000Z","categories_index":"Java","tags_index":"mybatis","author_index":"安安哎呀呀"},{"id":"144f0b4d9b9f80ea377106e9c6a54a45","title":"Linux基础","content":"一.基础指令​  file+文件名：查看文件类型 ；\n​  cat+文件名：查看文件；\n​  less + 文件名：分页查看文件；\n​  echo+内容：打印想要输出的内容;\n​  echo+内容&gt;文件名：打印内容至指定的文件里;\n​  ls +命令（错误的） 2&gt; 文件名： 重定向标准错误输出，即把指令输入错误的报错信息重定向保存至2&gt;后的文\n​  件中；重定向标准输出则为&lt;号；\n​  \n​  强制删除文件夹包括文件夹下的文件 ：rm -rf 文件夹名。\n​  查看防火墙状态：firewall-cmd –state；\n​  停止firewall： systemctl stop firewalld.service；\n​  禁止防火墙开机启动：systemctl disable firewalld.service；\n二.权限设置1.文件权限\n\n​  r指读权限，W指有写权限，-指无权限，x为执行权限。 ls -l +文件名:查看文件的权限情况。\n​ 2.添加权限（有权限代表1，无权限为0，共9位数，如上图，每3位代表R W X 读，写，执行权限，）\n​  例1： chmod +w 文件名；为当前操作目录的用户添加当前工作目录的写权限；\n​  chmod +r 文件名 ；添加读权限；\n​  chmod +x 文件名； 添加执行权限。\n​  例2： -rw-rw-r– 转化位二进制即 110  110  100 即要授予owner执行权限则需输入如下指令 (111 110 100) 111 二进制转化为十进制为 7 ，110转化为6 ，100转化为4。则指令应为\nchmod 764 +文件名或目录名。\n三.进程​  1.查看当前所有进程，并分页式输出(利用了管道)；\n​  例： ps aux|less\n​  2.查看附带模糊进程名；\n​  例： ps aux|grep vim 查询包含字符串vim的进程\n​  3.kill+进程ID结束指定的进程；\n\n​  kill -数字编号 进程ID 实现终止指定进程；\n​  例：kill -9 15 ，以编号9的方式终止15号进程。\n四.查找​  1.find 查出当前目录的所有文件；\n​  2.find+ |grep .txt 利用管道实现指定查找（筛选查找）；\n1)只想查看文件：find -type f\n​  2)只想查看目录：find -type d\n​  3)按类型查看的同时执行新的指令：find -type f -exec ls -l ‘{}’ ‘;’\n​  其中**-exec** 后为查找文件成功后想要执行的指令(本次查询完执行的指令为 ls -l ), **’;’**为-exec的结\n​  束符, **’{}’**代表查询到的文件。\n五.可执行文件​  1.ln -s a.sh test ：给可执行文件a.sh的别名为test;\n​  2. ./ a.sh ：执行a.sh这个可执行文件；\n六.配置JDK与下载各种软件​  1.yum install update ：更新系统中的package;\n​  2.curl + 网址 ：链接到网址(即打开对应的网站)；\n​  3.yum install +软件名：下载对应的应用软件;\n​  例： yum install wget 下载wget。\n​ 4.wget + 下载链接 ：下载；\n​  5.编辑文件结束后\n1）不想保存任何修改则输入 ：q!\n​  2）保存修改并退出则输入 ：wq\n​  6.配置JDK环境变量： vim /etc/profile (编辑配置文件) 需要输入的内容为（如下图）;\n\n​  7.使配置文件生效: source /etc/profile;\n​  8.解压文件：tar -zxvf 压缩包名 。\n​  9.进入到要安装得文件后执行编译安装指令: ./configure –prefix=/usr/local （其中–prefix=后为指定安装路径）,编译完后执行安装指令 make &amp;&amp; make install 。\n七.脚本​  可执行文件.sh中编写\n​  cd $1 \\\\链接到第一个文件\n​  echo I am in ‘pwq’  \\\\打印 I am in 当前工作目录路径 (其中‘ ’为tab键上的\\的一个按键，它会提取pwd指令的返回结果）\n​  for file in ‘ls’  \\对要操作的文件夹的文件全部替换名字，例a 执行脚本 后会变a.txt\n​  do\n​ 对应的操作\n​  done  \\结束脚本\n八.nginx\n cd /usr/local/sbin ：链接到此目录下；\n\n ./nginx ：启动nginx；\n\n ./nginx -s reload ：重启nginx（在没有配置全局变量的时候需要在nginx可执行目录sbin下，再输入此命令）；\n\n 验证nginx配置文件是否正确：进入nginx安装目录下的sbin下，输入**./nginx -t** ；\n\n停止nginx\n 1)ps -ef | grep nginx ;\n 2)从容停止nginx：kill -QUIT 主进程号；\n 3）快速停止：kill -TERM 主进程号；\n 4）强制停止 ：pkill -9 nginx 。\n\n\n九.Vim\n vim 开启行号：在命令模式下输入set number （即保存输入wq的位置输入set number按回车即可）；\n\n vim 关闭行号：set nonumber；\n\n\n","slug":"Linux基础","date":"2018-07-20T09:49:56.000Z","categories_index":"Linux","tags_index":"Linux","author_index":"安安哎呀呀"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites\n\n\n\n\n\n提示\n$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2018-07-20T07:49:56.000Z","categories_index":"Hexo","tags_index":"Hexo","author_index":"Ananya"}]